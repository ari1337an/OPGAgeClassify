{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "--T3qCwIPoWP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--T3qCwIPoWP",
    "outputId": "d28f0d75-e2c5-4215-95ce-5607c47aa5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch-summary in /usr/local/lib/python3.10/dist-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-metric-learning\n",
    "%pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdHENHQJkaNa",
   "metadata": {
    "id": "bdHENHQJkaNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "import getpass\n",
    "import math\n",
    "import numpy\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image,ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils.prune import l1_unstructured, random_unstructured\n",
    "import torch.nn.utils.prune as prune\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6C9vAiat-6F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6C9vAiat-6F",
    "outputId": "cdac6468-94ca-4423-a625-cc381f5f9d85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faeda17f310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "OxcfShJ_uDVs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxcfShJ_uDVs",
    "outputId": "60769655-ebee-49f9-df92-92faa1c9b020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ZTOkACl6d2s5",
   "metadata": {
    "id": "ZTOkACl6d2s5"
   },
   "outputs": [],
   "source": [
    "datasetA_save_dir = './datasetA'\n",
    "datasetB_save_dir = './datasetB'\n",
    "\n",
    "# Model Loading and training configurations settings\n",
    "load_best_first = True\n",
    "keep_initialization_records = True\n",
    "start_training_on_best_weights = True # Start Training with best weights\n",
    "\n",
    "# File Paths\n",
    "initial_best_model_path = './best_model@68.99%.pth'\n",
    "save_current_best_model_path = './current_best_model.pth'\n",
    "save_current_initializations = './current_initializations.pth'\n",
    "save_validation_accuracy_path = './val_acc.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdA042w3vQUk",
   "metadata": {
    "id": "fdA042w3vQUk"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(val):\n",
    "    arr = numpy.zeros((6,), dtype=int)\n",
    "    arr[val] = 1\n",
    "    return arr\n",
    "\n",
    "def get_bucket_id(age):\n",
    "  age_floor = int(age)\n",
    "  if age_floor >= 0 and age_floor <= 5: return 0\n",
    "  elif age_floor >= 6 and age_floor <= 12: return 1\n",
    "  elif age_floor >= 13 and age_floor <= 19: return 2\n",
    "  elif age_floor >= 20 and age_floor <= 29: return 3\n",
    "  elif age_floor >= 30 and age_floor <= 59: return 4\n",
    "  else: return 5\n",
    "\n",
    "def get_ground_truth(age):\n",
    "  return one_hot_encode(get_bucket_id(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "uVNdhyjdwbMM",
   "metadata": {
    "id": "uVNdhyjdwbMM"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_function, loss_optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Zeroing the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss_optimizer.zero_grad()\n",
    "\n",
    "        # Get Embeddings\n",
    "        embeddings = model(X)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(embeddings, y.argmax(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        loss_optimizer.step()\n",
    "\n",
    "        loss_tot += loss.item()\n",
    "        num += 1\n",
    "\n",
    "        del X\n",
    "        del y\n",
    "        del embeddings\n",
    "        del loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # loss_tot /= num\n",
    "    print(f'training loss: {(loss_tot):>0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "_eC3zycokwvy",
   "metadata": {
    "id": "_eC3zycokwvy"
   },
   "outputs": [],
   "source": [
    "def train_with_pseudo_label(dataloader, model, optimizer, loss_function, loss_optimizer, best_model):\n",
    "    torch.cuda.empty_cache()\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    tmp = 0\n",
    "    for batch, X in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        tmp = tmp + X.shape[0]\n",
    "\n",
    "        # Pseudo-Labelling\n",
    "        embedding = best_model(X)\n",
    "        logits = best_model.margin_loss_function.get_logits(embedding)\n",
    "        predSoftmax = nn.Softmax(dim=1)(logits)\n",
    "        pseudo_label = predSoftmax.argmax(1)\n",
    "\n",
    "        # Zeroing the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss_optimizer.zero_grad()\n",
    "\n",
    "        # Get Embeddings\n",
    "        embeddings = model(X)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(embeddings, pseudo_label)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        loss_optimizer.step()\n",
    "\n",
    "        loss_tot += loss.item()\n",
    "        num += 1\n",
    "\n",
    "        del X\n",
    "        del embedding\n",
    "        del logits\n",
    "        del predSoftmax\n",
    "        del pseudo_label\n",
    "        del embeddings\n",
    "        del loss\n",
    "        torch.cuda.empty_cache()\n",
    "    # loss_tot /= num\n",
    "    print(f'pseudo-label training loss: {(loss_tot):>0.5f}')\n",
    "    print(f'total-unlabelled-training: {tmp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "jEb-I15yD9OM",
   "metadata": {
    "id": "jEb-I15yD9OM"
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, path):\n",
    "    torch.save({\n",
    "      'model_state_dict': model.state_dict(),\n",
    "      'arcface_state_dict': model.margin_loss_function.state_dict(),\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "T40O9WsAXQzn",
   "metadata": {
    "id": "T40O9WsAXQzn"
   },
   "outputs": [],
   "source": [
    "def deep_copy_model(model_to_copy):\n",
    "    model_copy = copy.deepcopy(model_to_copy)\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "I9iNr-rLwdAb",
   "metadata": {
    "id": "I9iNr-rLwdAb"
   },
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "current_max_val_acc = 0.0\n",
    "def validation(dataloader, model, loss_function, dont_log = False):\n",
    "    global current_max_val_acc\n",
    "    global best_model\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    totalsize = 0\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward With Logits\n",
    "            embeddings = model(X)\n",
    "            logits = model.margin_loss_function.get_logits(embeddings)\n",
    "            predSoftmax = nn.Softmax(dim=1)(logits)\n",
    "            loss = model.margin_loss_function(embeddings,y.argmax(1))\n",
    "\n",
    "            correct += (predSoftmax.argmax(1) == y.argmax(1)).sum().item()\n",
    "            totalsize += predSoftmax.shape[0]\n",
    "            loss_tot += loss.item()\n",
    "            num += 1\n",
    "            X.cpu()\n",
    "            y.cpu()\n",
    "\n",
    "    print(f\"Correct/Total: {correct}/{totalsize}\")\n",
    "    correct /= totalsize\n",
    "    validation_accuracy.append(correct*100)\n",
    "    print(f\"Validation Loss:  {(loss_tot):>0.5f}\")\n",
    "    print(f\"Validation Accuracy: {(100*correct):>0.5f}%\\n\")\n",
    "\n",
    "    if 100*correct > current_max_val_acc and dont_log == False:\n",
    "        current_max_val_acc = 100*correct\n",
    "        save_model_checkpoint(model, save_current_best_model_path)\n",
    "        numpy.save(save_validation_accuracy_path, numpy.array(validation_accuracy), allow_pickle=True, fix_imports=True)\n",
    "        if correct > 67.0:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            print(\"Change best_model\")\n",
    "        print(\"Saved\")\n",
    "\n",
    "    print(f\"Current Best Validation Accuracy: {(current_max_val_acc):>0.5f}%\\n\")\n",
    "    return loss_tot, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77Hw6rVlvS8U",
   "metadata": {
    "id": "77Hw6rVlvS8U"
   },
   "outputs": [],
   "source": [
    "class XRayToothDatasetA(Dataset):\n",
    "    def __init__(self, cwd, img_dir, transform=None, target_height=None, target_width=None):\n",
    "        self.dataset_path = cwd + '/' + img_dir\n",
    "        self.transform = transform\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dataset_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx  >= len(os.listdir(self.dataset_path)):\n",
    "            print(\"No datafile/image at index : \"+ str(idx))\n",
    "            return None\n",
    "        img_filename = os.listdir(self.dataset_path)[idx]\n",
    "        age = float(img_filename.split(\"_\")[1][:-4])\n",
    "        age_gt = get_ground_truth(age)\n",
    "        image_tensor = read_image(path=self.dataset_path + '/' + img_filename)\n",
    "        image_tensor = image_tensor.reshape(1, 3, image_tensor.shape[-2], image_tensor.shape[-1])\n",
    "        if self.target_height and self.target_width: # Resize the image\n",
    "            image_tensor = torch.nn.functional.interpolate(image_tensor, (self.target_height,self.target_width))\n",
    "        if self.transform: image_tensor = self.transform(image_tensor) # Apply transformations\n",
    "        image_tensor = (image_tensor-image_tensor.min())/(image_tensor.max()-image_tensor.min())\n",
    "        return image_tensor.reshape(-1,image_tensor.shape[-2],image_tensor.shape[-1]).to(torch.float32), torch.tensor(age_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bGp7NjAhUebb",
   "metadata": {
    "id": "bGp7NjAhUebb"
   },
   "outputs": [],
   "source": [
    "# Gives only the unlabelled data\n",
    "class XRayToothDatasetB(Dataset):\n",
    "    def __init__(self, cwd, img_dir, transform=None, target_height=None, target_width=None):\n",
    "        self.dataset_path = cwd + '/' + img_dir\n",
    "        self.transform = transform\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dataset_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx  >= len(os.listdir(self.dataset_path)):\n",
    "            print(\"No datafile/image at index : \"+ str(idx))\n",
    "            return None\n",
    "        img_filename = os.listdir(self.dataset_path)[idx]\n",
    "        image_tensor = read_image(path=self.dataset_path + '/' + img_filename)\n",
    "        image_tensor = image_tensor.reshape(1, 3, image_tensor.shape[-2], image_tensor.shape[-1])\n",
    "        if self.target_height and self.target_width: # Resize the image\n",
    "            image_tensor = torch.nn.functional.interpolate(image_tensor, (self.target_height,self.target_width))\n",
    "        if self.transform: image_tensor = self.transform(image_tensor) # Apply transformations\n",
    "        image_tensor = (image_tensor-image_tensor.min())/(image_tensor.max()-image_tensor.min())\n",
    "        return image_tensor.reshape(-1,image_tensor.shape[-2],image_tensor.shape[-1]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GcLfF0ubvjzD",
   "metadata": {
    "id": "GcLfF0ubvjzD"
   },
   "outputs": [],
   "source": [
    "training_data = XRayToothDatasetA(os.getcwd(), img_dir=datasetA_save_dir+'/training', transform=None, target_height=224, target_width=224)\n",
    "validation_data = XRayToothDatasetA(os.getcwd(), img_dir=datasetA_save_dir+'/validation', transform=None, target_height=224, target_width=224)\n",
    "training_data_unlabelled = XRayToothDatasetB(os.getcwd(), img_dir=datasetB_save_dir+'/training', transform=None, target_height=224, target_width=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "xV_5gqVqbGbF",
   "metadata": {
    "id": "xV_5gqVqbGbF"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_l_32, ViT_L_32_Weights\n",
    "\n",
    "pretrained_vit = vit_l_32(weights=ViT_L_32_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7LCtItrLhBLc",
   "metadata": {
    "id": "7LCtItrLhBLc"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "pretrained_effnet = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7_GafBd2vsM0",
   "metadata": {
    "id": "7_GafBd2vsM0"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone1 = pretrained_vit\n",
    "        self.backbone2 = pretrained_effnet\n",
    "\n",
    "        for param in self.backbone1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.backbone2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(2000,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(512,256),\n",
    "        )\n",
    "\n",
    "        self.margin_loss_regularizer = regularizers.RegularFaceRegularizer()\n",
    "        self.margin_loss_function = losses.ArcFaceLoss(6, 256, margin=34.3, scale=1, weight_regularizer=self.margin_loss_regularizer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.backbone1(x)\n",
    "        x2 = self.backbone2(x)\n",
    "        x = torch.cat((x1,x2), 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "895zQ65zv-oO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "895zQ65zv-oO",
    "outputId": "f6834a94-4708-46bd-83bd-95ec31ed5504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model in best_model.\n",
      "Training will start with best weights till now!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "if keep_initialization_records == True: save_model_checkpoint(model, save_current_initializations) # Remember initializaion\n",
    "\n",
    "if load_best_first == True:\n",
    "    best_model = NeuralNetwork().to(device)\n",
    "    best_model.load_state_dict(torch.load(initial_best_model_path)['model_state_dict'])\n",
    "    best_model.margin_loss_function.load_state_dict(torch.load(initial_best_model_path)['arcface_state_dict'])\n",
    "    print(\"Loaded best model in best_model.\")\n",
    "else:\n",
    "    best_model = copy.deepcopy(model)\n",
    "    print(\"Didn't load best_model\")\n",
    "\n",
    "if start_training_on_best_weights == True:\n",
    "    model = deep_copy_model(best_model) # Start Training with best weights\n",
    "    print(\"Training will start with best weights till now!\")\n",
    "else:\n",
    "    print(\"Training will start with random weights.\")\n",
    "\n",
    "margin_loss_function = model.margin_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ZzpO5XU0wAmA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzpO5XU0wAmA",
    "outputId": "f9c38893-21a2-4657-d852-136e9de41b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1083, 0.1208, 0.1318, 0.2247, 0.2789, 0.1356]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test a forward pass\n",
    "with torch.no_grad():\n",
    "    embeddings = model(training_data[0][0].reshape(-1,3,224,224).to(device))\n",
    "    logits = model.margin_loss_function.get_logits(embeddings)\n",
    "    predSoftmax = nn.Softmax(dim=1)(logits)\n",
    "    print(predSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Xy5dsAcpwCri",
   "metadata": {
    "id": "Xy5dsAcpwCri"
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "short_epoch_limit = 1000\n",
    "batch_size = 500\n",
    "learning_rate = 3.8742e-04\n",
    "momentum=0.9\n",
    "weight_decay=0.9\n",
    "\n",
    "# Margin Loss Hyperparameters\n",
    "margin_loss_learning_rate = 3.8742e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "WhovjcHqwX91",
   "metadata": {
    "id": "WhovjcHqwX91"
   },
   "outputs": [],
   "source": [
    "trainingA_data_loader = DataLoader(training_data, batch_size, shuffle = True)\n",
    "validationA_data_loader = DataLoader(validation_data, batch_size, shuffle = False)\n",
    "trainingB_data_loader = DataLoader(training_data_unlabelled, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "YenD-SOUwRAV",
   "metadata": {
    "id": "YenD-SOUwRAV"
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "loss_optimizer = torch.optim.Adam(model.margin_loss_function.parameters(), lr=margin_loss_learning_rate)\n",
    "\n",
    "# Schedulers\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=5, min_lr=1e-7,verbose=True)\n",
    "margin_loss_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(loss_optimizer, 'min', factor=0.9, patience=5, min_lr=1e-7,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "zLPyZSm6efwF",
   "metadata": {
    "id": "zLPyZSm6efwF"
   },
   "outputs": [],
   "source": [
    "current_max_val_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "N-yF9ufgae_b",
   "metadata": {
    "id": "N-yF9ufgae_b"
   },
   "outputs": [],
   "source": [
    "significant_long_epochs_count = 0\n",
    "def run_long_epoch(model, best_model):\n",
    "    global significant_long_epochs_count\n",
    "    print(f\"Long Epoch {significant_long_epochs_count+1}\\n-------------------------------\")\n",
    "    # Pseudo Label and Train with that pseudo labelling\n",
    "    train_with_pseudo_label(trainingB_data_loader, model, optimizer, margin_loss_function, loss_optimizer, best_model)\n",
    "\n",
    "    # Validate on Dataset A's Validation Samples\n",
    "    val_loss,val_acc = validation(validationA_data_loader, model, margin_loss_function)\n",
    "    # scheduler2.step(val_loss)\n",
    "    # margin_loss_scheduler2.step(val_loss)\n",
    "\n",
    "    significant_long_epochs_count = significant_long_epochs_count + 1\n",
    "\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "itYQWKcBZGC-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itYQWKcBZGC-",
    "outputId": "1e699cfb-da6d-4934-ba8c-6f5613d4c2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Epoch 1\n",
      "-------------------------------\n",
      "training loss: 4.26254\n",
      "Correct/Total: 42/129\n",
      "Validation Loss:  2.30492\n",
      "Validation Accuracy: 32.55814%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 32.55814%\n",
      "\n",
      "Long Epoch 1\n",
      "-------------------------------\n",
      "pseudo-label training loss: 4.03958\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 38/129\n",
      "Validation Loss:  2.29103\n",
      "Validation Accuracy: 29.45736%\n",
      "\n",
      "Current Best Validation Accuracy: 32.55814%\n",
      "\n",
      "Short Epoch 2\n",
      "-------------------------------\n",
      "training loss: 4.23630\n",
      "Correct/Total: 41/129\n",
      "Validation Loss:  2.13293\n",
      "Validation Accuracy: 31.78295%\n",
      "\n",
      "Current Best Validation Accuracy: 32.55814%\n",
      "\n",
      "Long Epoch 2\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.72483\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 45/129\n",
      "Validation Loss:  2.09007\n",
      "Validation Accuracy: 34.88372%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 34.88372%\n",
      "\n",
      "Short Epoch 3\n",
      "-------------------------------\n",
      "training loss: 4.03782\n",
      "Correct/Total: 64/129\n",
      "Validation Loss:  1.92527\n",
      "Validation Accuracy: 49.61240%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 49.61240%\n",
      "\n",
      "Long Epoch 3\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.39434\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 56/129\n",
      "Validation Loss:  1.96139\n",
      "Validation Accuracy: 43.41085%\n",
      "\n",
      "Current Best Validation Accuracy: 49.61240%\n",
      "\n",
      "Short Epoch 4\n",
      "-------------------------------\n",
      "training loss: 3.94021\n",
      "Correct/Total: 62/129\n",
      "Validation Loss:  1.92661\n",
      "Validation Accuracy: 48.06202%\n",
      "\n",
      "Current Best Validation Accuracy: 49.61240%\n",
      "\n",
      "Long Epoch 4\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.22548\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 60/129\n",
      "Validation Loss:  1.95589\n",
      "Validation Accuracy: 46.51163%\n",
      "\n",
      "Current Best Validation Accuracy: 49.61240%\n",
      "\n",
      "Short Epoch 5\n",
      "-------------------------------\n",
      "training loss: 3.88772\n",
      "Correct/Total: 69/129\n",
      "Validation Loss:  1.89048\n",
      "Validation Accuracy: 53.48837%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 53.48837%\n",
      "\n",
      "Long Epoch 5\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.09544\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 63/129\n",
      "Validation Loss:  1.91579\n",
      "Validation Accuracy: 48.83721%\n",
      "\n",
      "Current Best Validation Accuracy: 53.48837%\n",
      "\n",
      "Short Epoch 6\n",
      "-------------------------------\n",
      "training loss: 3.85683\n",
      "Correct/Total: 63/129\n",
      "Validation Loss:  1.86724\n",
      "Validation Accuracy: 48.83721%\n",
      "\n",
      "Current Best Validation Accuracy: 53.48837%\n",
      "\n",
      "Long Epoch 6\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.06004\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 69/129\n",
      "Validation Loss:  1.86198\n",
      "Validation Accuracy: 53.48837%\n",
      "\n",
      "Current Best Validation Accuracy: 53.48837%\n",
      "\n",
      "Short Epoch 7\n",
      "-------------------------------\n",
      "training loss: 3.75755\n",
      "Correct/Total: 73/129\n",
      "Validation Loss:  1.82785\n",
      "Validation Accuracy: 56.58915%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 56.58915%\n",
      "\n",
      "Long Epoch 7\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.03505\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 68/129\n",
      "Validation Loss:  1.87047\n",
      "Validation Accuracy: 52.71318%\n",
      "\n",
      "Current Best Validation Accuracy: 56.58915%\n",
      "\n",
      "Short Epoch 8\n",
      "-------------------------------\n",
      "training loss: 3.67720\n",
      "Correct/Total: 76/129\n",
      "Validation Loss:  1.81070\n",
      "Validation Accuracy: 58.91473%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 58.91473%\n",
      "\n",
      "Long Epoch 8\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.01083\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 73/129\n",
      "Validation Loss:  1.84935\n",
      "Validation Accuracy: 56.58915%\n",
      "\n",
      "Current Best Validation Accuracy: 58.91473%\n",
      "\n",
      "Short Epoch 9\n",
      "-------------------------------\n",
      "training loss: 3.65277\n",
      "Correct/Total: 76/129\n",
      "Validation Loss:  1.80723\n",
      "Validation Accuracy: 58.91473%\n",
      "\n",
      "Current Best Validation Accuracy: 58.91473%\n",
      "\n",
      "Long Epoch 9\n",
      "-------------------------------\n",
      "pseudo-label training loss: 3.03137\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 73/129\n",
      "Validation Loss:  1.83541\n",
      "Validation Accuracy: 56.58915%\n",
      "\n",
      "Current Best Validation Accuracy: 58.91473%\n",
      "\n",
      "Short Epoch 10\n",
      "-------------------------------\n",
      "training loss: 3.55832\n",
      "Correct/Total: 74/129\n",
      "Validation Loss:  1.76620\n",
      "Validation Accuracy: 57.36434%\n",
      "\n",
      "Current Best Validation Accuracy: 58.91473%\n",
      "\n",
      "Long Epoch 10\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.98338\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 76/129\n",
      "Validation Loss:  1.84045\n",
      "Validation Accuracy: 58.91473%\n",
      "\n",
      "Current Best Validation Accuracy: 58.91473%\n",
      "\n",
      "Short Epoch 11\n",
      "-------------------------------\n",
      "training loss: 3.50596\n",
      "Correct/Total: 79/129\n",
      "Validation Loss:  1.78450\n",
      "Validation Accuracy: 61.24031%\n",
      "\n",
      "Saved\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 11\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.93594\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 75/129\n",
      "Validation Loss:  1.78869\n",
      "Validation Accuracy: 58.13953%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 12\n",
      "-------------------------------\n",
      "training loss: 3.42726\n",
      "Correct/Total: 76/129\n",
      "Validation Loss:  1.76308\n",
      "Validation Accuracy: 58.91473%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 12\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.93937\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 62/129\n",
      "Validation Loss:  1.87839\n",
      "Validation Accuracy: 48.06202%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 13\n",
      "-------------------------------\n",
      "training loss: 3.43673\n",
      "Correct/Total: 75/129\n",
      "Validation Loss:  1.76954\n",
      "Validation Accuracy: 58.13953%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 13\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.92466\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 68/129\n",
      "Validation Loss:  1.86779\n",
      "Validation Accuracy: 52.71318%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 14\n",
      "-------------------------------\n",
      "training loss: 3.40035\n",
      "Correct/Total: 75/129\n",
      "Validation Loss:  1.78989\n",
      "Validation Accuracy: 58.13953%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 14\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.90854\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 71/129\n",
      "Validation Loss:  1.82959\n",
      "Validation Accuracy: 55.03876%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 15\n",
      "-------------------------------\n",
      "training loss: 3.39848\n",
      "Correct/Total: 71/129\n",
      "Validation Loss:  1.78097\n",
      "Validation Accuracy: 55.03876%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 15\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.89987\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 71/129\n",
      "Validation Loss:  1.85190\n",
      "Validation Accuracy: 55.03876%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 16\n",
      "-------------------------------\n",
      "training loss: 3.35386\n",
      "Correct/Total: 78/129\n",
      "Validation Loss:  1.81765\n",
      "Validation Accuracy: 60.46512%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 16\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.98143\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 63/129\n",
      "Validation Loss:  1.88917\n",
      "Validation Accuracy: 48.83721%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 17\n",
      "-------------------------------\n",
      "training loss: 3.39605\n",
      "Correct/Total: 75/129\n",
      "Validation Loss:  1.79260\n",
      "Validation Accuracy: 58.13953%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 17\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.84647\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 72/129\n",
      "Validation Loss:  1.80363\n",
      "Validation Accuracy: 55.81395%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 18\n",
      "-------------------------------\n",
      "training loss: 3.36713\n",
      "Correct/Total: 72/129\n",
      "Validation Loss:  1.79895\n",
      "Validation Accuracy: 55.81395%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 18\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.87243\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  1.86860\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 19\n",
      "-------------------------------\n",
      "training loss: 3.37399\n",
      "Correct/Total: 66/129\n",
      "Validation Loss:  1.86537\n",
      "Validation Accuracy: 51.16279%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 19\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.83165\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 63/129\n",
      "Validation Loss:  1.95015\n",
      "Validation Accuracy: 48.83721%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 20\n",
      "-------------------------------\n",
      "training loss: 3.38134\n",
      "Correct/Total: 71/129\n",
      "Validation Loss:  1.81825\n",
      "Validation Accuracy: 55.03876%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 20\n",
      "-------------------------------\n",
      "pseudo-label training loss: 2.88827\n",
      "total-unlabelled-training: 1000\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  1.85257\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Short Epoch 21\n",
      "-------------------------------\n",
      "training loss: 3.35306\n",
      "Correct/Total: 70/129\n",
      "Validation Loss:  1.80624\n",
      "Validation Accuracy: 54.26357%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Long Epoch 21\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for t in range(short_epoch_limit):\n",
    "    print(f\"Short Epoch {t+1}\\n-------------------------------\")\n",
    "    # Train @ alpha on Dataset A's Training Samples\n",
    "    train(trainingA_data_loader, model, optimizer, margin_loss_function, loss_optimizer)\n",
    "\n",
    "    # Validate on Dataset A's Validation Samples\n",
    "    val_loss,val_acc = validation(validationA_data_loader, model, margin_loss_function)\n",
    "    # scheduler2.step(val_loss)\n",
    "    # margin_loss_scheduler2.step(val_loss)\n",
    "\n",
    "    # Run Long Epoch\n",
    "    run_long_epoch(model, best_model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GswM5udqQv4S",
   "metadata": {
    "id": "GswM5udqQv4S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
