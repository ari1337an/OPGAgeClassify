{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "WpCAGQa5_yxX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpCAGQa5_yxX",
    "outputId": "d0f14883-00f1-46eb-b13a-204c528f1fec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-metric-learning\n",
      "  Downloading pytorch_metric_learning-2.1.2-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Installing collected packages: pytorch-metric-learning\n",
      "Successfully installed pytorch-metric-learning-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdHENHQJkaNa",
   "metadata": {
    "id": "bdHENHQJkaNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "import getpass\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image,ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from torchsummary import summary\n",
    "from torchvision.models.vision_transformer import VisionTransformer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6C9vAiat-6F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6C9vAiat-6F",
    "outputId": "a9b31e53-a8cb-4dd0-c267-9dc18161ede6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5f5054a710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "OxcfShJ_uDVs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxcfShJ_uDVs",
    "outputId": "e9b62e7a-6481-4fbc-fb39-c98ca12a6a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34eec6dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34eec6dc",
    "outputId": "94b57bc7-becc-47ba-9900-87ecfdac8eb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5e89f0afb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_generator = torch.Generator(device='cpu')\n",
    "random_generator.manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ZTOkACl6d2s5",
   "metadata": {
    "id": "ZTOkACl6d2s5"
   },
   "outputs": [],
   "source": [
    "dataset_save_dir = './dataset'\n",
    "\n",
    "# File Paths\n",
    "save_current_best_model_path = './triplet_classifier_model.pth'\n",
    "save_validation_accuracy_path = './triplet_classifier_model_val_acc.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdA042w3vQUk",
   "metadata": {
    "id": "fdA042w3vQUk"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(val):\n",
    "    arr = numpy.zeros((6,), dtype=int)\n",
    "    arr[val] = 1\n",
    "    return arr\n",
    "\n",
    "def get_bucket_id(age):\n",
    "  age_floor = int(age)\n",
    "  if age_floor >= 0 and age_floor <= 5: return 0\n",
    "  elif age_floor >= 6 and age_floor <= 12: return 1\n",
    "  elif age_floor >= 13 and age_floor <= 19: return 2\n",
    "  elif age_floor >= 20 and age_floor <= 29: return 3\n",
    "  elif age_floor >= 30 and age_floor <= 59: return 4\n",
    "  else: return 5\n",
    "\n",
    "def get_ground_truth(age):\n",
    "  return one_hot_encode(get_bucket_id(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "VbbhYSphI1C_",
   "metadata": {
    "id": "VbbhYSphI1C_"
   },
   "outputs": [],
   "source": [
    "def get_random_two_different_int(low=0, high=6, size=1):\n",
    "  num1 = torch.randint(low,high, (size,), generator=random_generator).item()\n",
    "  num2 = torch.randint(low,high, (size,), generator=random_generator).item()\n",
    "  while num1 == num2: num2 = torch.randint(low,high, (size,), generator=random_generator).item()\n",
    "  return num1,num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb458000",
   "metadata": {
    "id": "fb458000"
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, path):\n",
    "    torch.save({\n",
    "      'model_state_dict': model.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def deep_copy_model(model_to_copy):\n",
    "    model_copy = copy.deepcopy(model_to_copy)\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b48176a",
   "metadata": {
    "id": "7b48176a"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Find all embeddings of current batch\n",
    "        embeddings = model.get_embedding(X)\n",
    "        del X\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Mining the farthest positive and closest negative\n",
    "        dist_matrix = torch.cdist(embeddings,embeddings)\n",
    "        mask_positive = (y.unsqueeze(1) == y.unsqueeze(0)).float()\n",
    "        dist_for_only_positive = ((1-mask_positive)*-2e8)+mask_positive*dist_matrix\n",
    "        positives = embeddings[dist_for_only_positive.argmax(dim=1)]\n",
    "        del dist_for_only_positive\n",
    "        torch.cuda.empty_cache()\n",
    "        dist_for_only_negative = (mask_positive*2e8)+(1-mask_positive)*dist_matrix\n",
    "        del mask_positive\n",
    "        del dist_matrix\n",
    "        torch.cuda.empty_cache()\n",
    "        negatives = embeddings[dist_for_only_negative.argmin(dim=1)]\n",
    "        del dist_for_only_negative\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Finding logits of current batch\n",
    "        logits = model.get_logit(embeddings)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits, embeddings, positives, negatives, y, 1.0, 1.0)\n",
    "        del logits\n",
    "        del positives\n",
    "        del negatives\n",
    "        del y\n",
    "        del embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_tot += loss.item()\n",
    "        num += 1\n",
    "    print(f'training loss: {(loss_tot):>0.5f}')\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6n5kMmXgzceg",
   "metadata": {
    "id": "6n5kMmXgzceg"
   },
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "current_max_val_acc = 0.0\n",
    "def validation(dataloader, model, loss_fn, dont_log = False):\n",
    "    global current_max_val_acc\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    totalsize = 0\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            validation_size = X.shape[0]\n",
    "\n",
    "            # Get all the embeddings; make sure to set batchsize max\n",
    "            embeddings = model.get_embedding(X)\n",
    "            anchors = embeddings.unsqueeze(1).expand(-1, validation_size, -1).reshape(-1, embeddings.size(1))\n",
    "            versus = embeddings.repeat(validation_size,1)\n",
    "            del embeddings\n",
    "            torch.cuda.empty_cache()\n",
    "            # similarities = model.get_similarity(anchors, versus).reshape(validation_size, -1).argmax(dim=1)\n",
    "            similarities = model.get_similarity(anchors, versus).reshape(validation_size, -1)\n",
    "            mask = torch.ones((validation_size,validation_size))\n",
    "            indices = torch.arange(validation_size)\n",
    "            similarities[indices, indices] = -2e8 # assign -INF for same samples\n",
    "            similarities = similarities.argmax(dim=1)\n",
    "            del anchors\n",
    "            del versus\n",
    "            torch.cuda.empty_cache()\n",
    "            predicted_labels = y[similarities]\n",
    "            del similarities\n",
    "            torch.cuda.empty_cache()\n",
    "            num_equal_indices = torch.nonzero(predicted_labels == y).squeeze().numel()\n",
    "            del predicted_labels\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            print(num_equal_indices)\n",
    "\n",
    "            correct += num_equal_indices\n",
    "            totalsize += X.shape[0]\n",
    "            cnt += X.shape[0]\n",
    "            num += 1\n",
    "            del X\n",
    "            del y\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Correct/Total: {correct}/{totalsize}\")\n",
    "    correct /= totalsize\n",
    "    validation_accuracy.append(correct*100)\n",
    "    # print(f\"Validation Loss:  {(loss_tot):>0.5f}\")\n",
    "    print(f\"Validation Accuracy: {(100*correct):>0.5f}%\\n\")\n",
    "    print(f\"Total images: {cnt}\")\n",
    "    if 100*correct > current_max_val_acc and dont_log == False:\n",
    "        current_max_val_acc = 100*correct\n",
    "        save_model_checkpoint(model, save_current_best_model_path)\n",
    "        numpy.save(save_validation_accuracy_path, numpy.array(validation_accuracy), allow_pickle=True, fix_imports=True)\n",
    "        print(\"Saved\")\n",
    "\n",
    "    print(f\"Current Best Validation Accuracy: {(current_max_val_acc):>0.5f}%\\n\")\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "AHwUHW0XvX0s",
   "metadata": {
    "id": "AHwUHW0XvX0s"
   },
   "outputs": [],
   "source": [
    "data_augmentation_transformations = T.RandomChoice([ # Geometric Transformation\n",
    "    T.RandomAffine(degrees=0),\n",
    "    T.Lambda(lambda x: TF.hflip(img=x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "kTyfSsFwoNqO",
   "metadata": {
    "id": "kTyfSsFwoNqO"
   },
   "outputs": [],
   "source": [
    "class XRayToothDataset(Dataset):\n",
    "    def __init__(self, cwd, img_dir, transform=None, target_height=None, target_width=None):\n",
    "        self.dataset_path = cwd + '/' + img_dir\n",
    "        self.transform = transform\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dataset_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx  >= len(os.listdir(self.dataset_path)):\n",
    "            print(\"No datafile/image at index : \"+ str(idx))\n",
    "            return None\n",
    "        img_filename = os.listdir(self.dataset_path)[idx]\n",
    "        age = float(img_filename.split(\"_\")[1][:-4])\n",
    "        age_gt = get_bucket_id(age)\n",
    "        image_tensor = read_image(path=self.dataset_path + '/' + img_filename)\n",
    "        image_tensor = image_tensor.reshape(1, 3, image_tensor.shape[-2], image_tensor.shape[-1])\n",
    "        if self.target_height and self.target_width: # Resize the image\n",
    "            image_tensor = torch.nn.functional.interpolate(image_tensor, (self.target_height,self.target_width))\n",
    "        if self.transform: image_tensor = self.transform(image_tensor) # Apply transformations\n",
    "        image_tensor = (image_tensor-image_tensor.min())/(image_tensor.max()-image_tensor.min())\n",
    "        return image_tensor.reshape(-1,image_tensor.shape[-2],image_tensor.shape[-1]).to(torch.float32), torch.tensor(age_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "GcLfF0ubvjzD",
   "metadata": {
    "id": "GcLfF0ubvjzD"
   },
   "outputs": [],
   "source": [
    "training_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/training', transform=data_augmentation_transformations, target_height=224, target_width=224)\n",
    "validation_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/validation', transform=None, target_height=224, target_width=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "z81w3rs4qDpo",
   "metadata": {
    "id": "z81w3rs4qDpo"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_l_32, ViT_L_32_Weights\n",
    "\n",
    "pretrained_vit = vit_l_32(weights=ViT_L_32_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "Pghb6DR8qFF3",
   "metadata": {
    "id": "Pghb6DR8qFF3"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "pretrained_effnet = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7_GafBd2vsM0",
   "metadata": {
    "id": "7_GafBd2vsM0"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone1 = pretrained_vit\n",
    "        self.backbone2 = pretrained_effnet\n",
    "        for param in self.backbone1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.backbone2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(2000,256)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def get_embedding(self, x): # Embedding of only single image\n",
    "        x1 = self.backbone1(x)\n",
    "        x2 = self.backbone2(x)\n",
    "        x = torch.cat((x1,x2), 1)\n",
    "        e = self.fc(x)\n",
    "        return e\n",
    "\n",
    "    def get_logit(self, ea):\n",
    "        logit = self.classifier(ea)\n",
    "        return logit\n",
    "\n",
    "    def get_softmax(self, logit):\n",
    "        probabilities = nn.Softmax(dim=1)(logit)\n",
    "        return probabilities\n",
    "\n",
    "    def get_similarity(self, e1, e2):\n",
    "        return nn.CosineSimilarity(dim=1)(e1, e2)\n",
    "\n",
    "    def forward(self, xA, xP, xN): # Get three embeddings\n",
    "        ea = self.get_embedding(xA)\n",
    "        ep = self.get_embedding(xP)\n",
    "        en = self.get_embedding(xN)\n",
    "        return ea, ep, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "895zQ65zv-oO",
   "metadata": {
    "id": "895zQ65zv-oO"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "Xy5dsAcpwCri",
   "metadata": {
    "id": "Xy5dsAcpwCri"
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "epochs = 10000\n",
    "batch_size = 1000\n",
    "learning_rate = 1e-2\n",
    "momentum=0.9\n",
    "weight_decay=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "WhovjcHqwX91",
   "metadata": {
    "id": "WhovjcHqwX91"
   },
   "outputs": [],
   "source": [
    "training_data_loader = DataLoader(training_data, batch_size, shuffle = True)\n",
    "validation_data_loader = DataLoader(validation_data, 129, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2492025b",
   "metadata": {
    "id": "2492025b"
   },
   "outputs": [],
   "source": [
    "class CustomNLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits, anchors, positives, negatives, labels, scale1, scale2):\n",
    "        loss_c = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        loss_t = nn.TripletMarginLoss(margin=10.0)(anchors,positives,negatives)\n",
    "        loss_total = scale1*loss_c + scale2*loss_t\n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "YenD-SOUwRAV",
   "metadata": {
    "id": "YenD-SOUwRAV"
   },
   "outputs": [],
   "source": [
    "loss_function=CustomNLLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=5, min_lr=1e-4,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7NVlZBIwh-F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7NVlZBIwh-F",
    "outputId": "bde50b82-fcbf-4597-db9a-48e6425a1859",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "training loss: 18.57322\n",
      "tensor([  6,  80, 115, 113,  21,  56,  72, 109,  80, 117,  49,   8,  31,  30,\n",
      "        122,   4,  21, 102,  96, 124,  55,   2, 115, 126,  34,  20,  39,  95,\n",
      "         13,  91,  13,  62, 117, 101,  68,  58, 122, 124,  67,  13,  46, 113,\n",
      "         64,  40,  68, 102,  64,  58,  69, 114, 103, 113, 113,  44,  97,  20,\n",
      "         97,  74,  35, 115,  74,  35,  31,  31,  46, 100,   9,  63,  34,  31,\n",
      "        101,  58,   6,  99,  89,  91,  71,  50,  13,  61,   8,  98,   8,  70,\n",
      "         31,  35, 113,  15,  89, 113, 111,  23,  36,  55, 122,  27,  21,  54,\n",
      "         21, 102,  30,  70, 126,   8,  23,  35, 113,  13, 114,   0, 115,  90,\n",
      "        118, 122,  49,   2,  35,  55, 112,  30, 117,  99, 113,  63,  31,  23,\n",
      "         54,  64,   2], device='cuda:0')\n",
      "62\n",
      "Correct/Total: 62/129\n",
      "Validation Accuracy: 48.06202%\n",
      "\n",
      "Total images: 129\n",
      "Saved\n",
      "Current Best Validation Accuracy: 48.06202%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(training_data_loader, model, loss_function, optimizer)\n",
    "    if t >= 100: # 20 warmup epochs\n",
    "        validation(validation_data_loader, model, loss_function)\n",
    "        scheduler.step(train_loss)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
