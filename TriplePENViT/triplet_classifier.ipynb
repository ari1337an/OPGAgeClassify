{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WpCAGQa5_yxX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpCAGQa5_yxX",
    "outputId": "b064f70b-5d24-4afc-e49c-e3aed12f1f03"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdHENHQJkaNa",
   "metadata": {
    "id": "bdHENHQJkaNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "import getpass\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image,ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from torchsummary import summary\n",
    "from torchvision.models.vision_transformer import VisionTransformer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6C9vAiat-6F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6C9vAiat-6F",
    "outputId": "7949a3e4-7335-4ac0-dce2-ccde6012931b"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OxcfShJ_uDVs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxcfShJ_uDVs",
    "outputId": "a525c16b-ae08-4beb-b362-a5152b5c5d26"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eec6dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34eec6dc",
    "outputId": "c3fc4d5e-5671-4e3b-ec7a-3fc3ad0885f9"
   },
   "outputs": [],
   "source": [
    "random_generator = torch.Generator(device='cpu')\n",
    "random_generator.manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZTOkACl6d2s5",
   "metadata": {
    "id": "ZTOkACl6d2s5"
   },
   "outputs": [],
   "source": [
    "dataset_save_dir = './dataset'\n",
    "\n",
    "# File Paths\n",
    "save_current_best_model_path = './triplet_classifier_model.pth'\n",
    "save_validation_accuracy_path = './triplet_classifier_model_val_acc.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdA042w3vQUk",
   "metadata": {
    "id": "fdA042w3vQUk"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(val):\n",
    "    arr = numpy.zeros((6,), dtype=int)\n",
    "    arr[val] = 1\n",
    "    return arr\n",
    "\n",
    "def get_bucket_id(age):\n",
    "  age_floor = int(age)\n",
    "  if age_floor >= 0 and age_floor <= 5: return 0\n",
    "  elif age_floor >= 6 and age_floor <= 12: return 1\n",
    "  elif age_floor >= 13 and age_floor <= 19: return 2\n",
    "  elif age_floor >= 20 and age_floor <= 29: return 3\n",
    "  elif age_floor >= 30 and age_floor <= 59: return 4\n",
    "  else: return 5\n",
    "\n",
    "def get_ground_truth(age):\n",
    "  return one_hot_encode(get_bucket_id(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VbbhYSphI1C_",
   "metadata": {
    "id": "VbbhYSphI1C_"
   },
   "outputs": [],
   "source": [
    "def get_random_two_different_int(low=0, high=6, size=1):\n",
    "  num1 = torch.randint(low,high, (size,), generator=random_generator).item()\n",
    "  num2 = torch.randint(low,high, (size,), generator=random_generator).item()\n",
    "  while num1 == num2: num2 = torch.randint(low,high, (size,), generator=random_generator).item()\n",
    "  return num1,num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb458000",
   "metadata": {
    "id": "fb458000"
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, path):\n",
    "    torch.save({\n",
    "      'model_state_dict': model.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def deep_copy_model(model_to_copy):\n",
    "    model_copy = copy.deepcopy(model_to_copy)\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48176a",
   "metadata": {
    "id": "7b48176a"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Find all embeddings of current batch\n",
    "        embeddings = model.get_embedding(X)\n",
    "        del X\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Mining the farthest positive and closest negative\n",
    "        dist_matrix = torch.cdist(embeddings,embeddings)\n",
    "        mask_positive = (y.unsqueeze(1) == y.unsqueeze(0)).float()\n",
    "        dist_for_only_positive = ((1-mask_positive)*-2e8)+mask_positive*dist_matrix\n",
    "        positives = embeddings[dist_for_only_positive.argmax(dim=1)]\n",
    "        del dist_for_only_positive\n",
    "        torch.cuda.empty_cache()\n",
    "        dist_for_only_negative = (mask_positive*2e8)+(1-mask_positive)*dist_matrix\n",
    "        del mask_positive\n",
    "        del dist_matrix\n",
    "        torch.cuda.empty_cache()\n",
    "        negatives = embeddings[dist_for_only_negative.argmin(dim=1)]\n",
    "        del dist_for_only_negative\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Finding logits of current batch\n",
    "        logits = model.get_logit(embeddings)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits, embeddings, positives, negatives, y, 1.0, 1.0)\n",
    "        del logits\n",
    "        del positives\n",
    "        del negatives\n",
    "        del y\n",
    "        del embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_tot += loss.item()\n",
    "        num += 1\n",
    "    print(f'training loss: {(loss_tot):>0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5a2e2",
   "metadata": {
    "id": "85d5a2e2"
   },
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "current_max_val_acc = 0.0\n",
    "def validation(dataloader, model, loss_fn, dont_log = False):\n",
    "    global current_max_val_acc\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    totalsize = 0\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            embeddings = model.get_embedding(X)\n",
    "            logits = model.get_logit(embeddings)\n",
    "            probabilities = model.get_softmax(logits)\n",
    "            loss = loss_fn(logits=logits, labels=y)\n",
    "            correct += (probabilities.argmax(1) == y).sum().item()\n",
    "            totalsize += X.shape[0]\n",
    "            cnt += X.shape[0]\n",
    "            loss_tot += loss.item()\n",
    "            num += 1\n",
    "            del X\n",
    "            del y\n",
    "            del embeddings\n",
    "            del logits\n",
    "            del probabilities\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Correct/Total: {correct}/{totalsize}\")\n",
    "    correct /= totalsize\n",
    "    validation_accuracy.append(correct*100)\n",
    "    print(f\"Validation Loss:  {(loss_tot):>0.5f}\")\n",
    "    print(f\"Validation Accuracy: {(100*correct):>0.5f}%\\n\")\n",
    "    print(f\"Total images: {cnt}\")\n",
    "    if 100*correct > current_max_val_acc and dont_log == False:\n",
    "        current_max_val_acc = 100*correct\n",
    "        save_model_checkpoint(model, save_current_best_model_path)\n",
    "        numpy.save(save_validation_accuracy_path, numpy.array(validation_accuracy), allow_pickle=True, fix_imports=True)\n",
    "        print(\"Saved\")\n",
    "\n",
    "    print(f\"Current Best Validation Accuracy: {(current_max_val_acc):>0.5f}%\\n\")\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AHwUHW0XvX0s",
   "metadata": {
    "id": "AHwUHW0XvX0s"
   },
   "outputs": [],
   "source": [
    "data_augmentation_transformations = T.RandomChoice([ # Geometric Transformation\n",
    "    T.RandomAffine(degrees=0),\n",
    "    T.Lambda(lambda x: TF.hflip(img=x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kTyfSsFwoNqO",
   "metadata": {
    "id": "kTyfSsFwoNqO"
   },
   "outputs": [],
   "source": [
    "class XRayToothDataset(Dataset):\n",
    "    def __init__(self, cwd, img_dir, transform=None, target_height=None, target_width=None):\n",
    "        self.dataset_path = cwd + '/' + img_dir\n",
    "        self.transform = transform\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dataset_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx  >= len(os.listdir(self.dataset_path)):\n",
    "            print(\"No datafile/image at index : \"+ str(idx))\n",
    "            return None\n",
    "        img_filename = os.listdir(self.dataset_path)[idx]\n",
    "        age = float(img_filename.split(\"_\")[1][:-4])\n",
    "        age_gt = get_bucket_id(age)\n",
    "        image_tensor = read_image(path=self.dataset_path + '/' + img_filename)\n",
    "        image_tensor = image_tensor.reshape(1, 3, image_tensor.shape[-2], image_tensor.shape[-1])\n",
    "        if self.target_height and self.target_width: # Resize the image\n",
    "            image_tensor = torch.nn.functional.interpolate(image_tensor, (self.target_height,self.target_width))\n",
    "        if self.transform: image_tensor = self.transform(image_tensor) # Apply transformations\n",
    "        image_tensor = (image_tensor-image_tensor.min())/(image_tensor.max()-image_tensor.min())\n",
    "        return image_tensor.reshape(-1,image_tensor.shape[-2],image_tensor.shape[-1]).to(torch.float32), torch.tensor(age_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GcLfF0ubvjzD",
   "metadata": {
    "id": "GcLfF0ubvjzD"
   },
   "outputs": [],
   "source": [
    "training_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/training', transform=data_augmentation_transformations, target_height=224, target_width=224)\n",
    "validation_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/validation', transform=None, target_height=224, target_width=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2wUNgTEXCyLj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wUNgTEXCyLj",
    "outputId": "cda7d9b4-52ff-4564-afcc-4ec0de729946"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_l_32, ViT_L_32_Weights\n",
    "\n",
    "pretrained_vit = vit_l_32(weights=ViT_L_32_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7_GafBd2vsM0",
   "metadata": {
    "id": "7_GafBd2vsM0"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = pretrained_vit\n",
    "        pretrained_vit.heads.head = nn.Linear(1024,256)\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        pretrained_vit.heads.head.requires_grad = True\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def get_embedding(self, x): # Embedding of only single image\n",
    "        e = self.backbone(x)\n",
    "        return e\n",
    "\n",
    "    def get_logit(self, ea):\n",
    "        logit = self.classifier(ea)\n",
    "        return logit\n",
    "\n",
    "    def get_softmax(self, logit):\n",
    "        probabilities = nn.Softmax(dim=1)(logit)\n",
    "        return probabilities\n",
    "\n",
    "    def forward(self, xA, xP, xN): # Get three embeddings\n",
    "        ea = self.get_embedding(xA)\n",
    "        ep = self.get_embedding(xP)\n",
    "        en = self.get_embedding(xN)\n",
    "        return ea, ep, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895zQ65zv-oO",
   "metadata": {
    "id": "895zQ65zv-oO"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xy5dsAcpwCri",
   "metadata": {
    "id": "Xy5dsAcpwCri"
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "epochs = 10000\n",
    "batch_size = 300\n",
    "learning_rate = 1e-2\n",
    "momentum=0.9\n",
    "weight_decay=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WhovjcHqwX91",
   "metadata": {
    "id": "WhovjcHqwX91"
   },
   "outputs": [],
   "source": [
    "training_data_loader = DataLoader(training_data, batch_size, shuffle = True)\n",
    "validation_data_loader = DataLoader(validation_data, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492025b",
   "metadata": {
    "id": "2492025b"
   },
   "outputs": [],
   "source": [
    "class CustomNLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits, anchors=None, positives=None, negatives=None, labels=None, scale1=None, scale2=None):\n",
    "        loss_c = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        if anchors==None: return loss_c\n",
    "        loss_t = nn.TripletMarginLoss(margin=1.0)(anchors,positives,negatives)\n",
    "        loss_total = scale1*loss_c + scale2*loss_t\n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YenD-SOUwRAV",
   "metadata": {
    "id": "YenD-SOUwRAV"
   },
   "outputs": [],
   "source": [
    "loss_function=CustomNLLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=5, min_lr=1e-4,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7NVlZBIwh-F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7NVlZBIwh-F",
    "outputId": "c525360c-e940-4663-9c6c-982811e63357",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(training_data_loader, model, loss_function, optimizer)\n",
    "    if t >= 100: # 20 warmup epochs\n",
    "        val_loss = validation(validation_data_loader, model, loss_function)\n",
    "        scheduler.step(val_loss)\n",
    "    # torch.save(model, 'model.pth')\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
