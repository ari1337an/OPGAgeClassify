{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kgTCEDXzibaZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgTCEDXzibaZ",
    "outputId": "2e5d439a-71ea-4a35-8424-1d28f13c1531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.0.0+cu118)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdHENHQJkaNa",
   "metadata": {
    "id": "bdHENHQJkaNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "import getpass\n",
    "import math\n",
    "import numpy\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image,ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6C9vAiat-6F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6C9vAiat-6F",
    "outputId": "b4b85225-ae38-4fdf-fb92-17553bc26588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f430ff90790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "OxcfShJ_uDVs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxcfShJ_uDVs",
    "outputId": "5cafb631-f324-4e42-a9ca-2af061bae05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ZTOkACl6d2s5",
   "metadata": {
    "id": "ZTOkACl6d2s5"
   },
   "outputs": [],
   "source": [
    "dataset_save_dir = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdA042w3vQUk",
   "metadata": {
    "id": "fdA042w3vQUk"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(val):\n",
    "    arr = numpy.zeros((6,), dtype=int)\n",
    "    arr[val] = 1\n",
    "    return arr\n",
    "\n",
    "def get_bucket_id(age):\n",
    "  age_floor = int(age)\n",
    "  if age_floor >= 0 and age_floor <= 5: return 0\n",
    "  elif age_floor >= 6 and age_floor <= 12: return 1\n",
    "  elif age_floor >= 13 and age_floor <= 19: return 2\n",
    "  elif age_floor >= 20 and age_floor <= 29: return 3\n",
    "  elif age_floor >= 30 and age_floor <= 59: return 4\n",
    "  else: return 5\n",
    "\n",
    "def get_ground_truth(age):\n",
    "  return one_hot_encode(get_bucket_id(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uVNdhyjdwbMM",
   "metadata": {
    "id": "uVNdhyjdwbMM"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_function, loss_optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Zeroing the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss_optimizer.zero_grad()\n",
    "\n",
    "        # Get Embeddings\n",
    "        embeddings = model(X)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(embeddings, y.argmax(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        loss_optimizer.step()\n",
    "\n",
    "        loss_tot += loss.item()\n",
    "        num += 1\n",
    "        \n",
    "        X.cpu()\n",
    "        y.cpu()\n",
    "\n",
    "    # loss_tot /= num\n",
    "    print(f'training loss: {(loss_tot):>0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "I9iNr-rLwdAb",
   "metadata": {
    "id": "I9iNr-rLwdAb"
   },
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "current_max_val_acc = 0.0\n",
    "def validation(dataloader, model, loss_function):\n",
    "    global current_max_val_acc\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    totalsize = 0\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward With Logits\n",
    "            embeddings = model(X)        \n",
    "            logits = loss_function.get_logits(embeddings)\n",
    "            predSoftmax = nn.Softmax(dim=1)(logits)\n",
    "            loss = loss_function(embeddings,y.argmax(1))\n",
    "            \n",
    "            correct += (predSoftmax.argmax(1) == y.argmax(1)).sum().item()\n",
    "            totalsize += predSoftmax.shape[0]\n",
    "            loss_tot += loss.item()\n",
    "            num += 1\n",
    "            X.cpu()\n",
    "            y.cpu()\n",
    "            \n",
    "    print(f\"Correct/Total: {correct}/{totalsize}\")\n",
    "    correct /= totalsize\n",
    "    validation_accuracy.append(correct*100)\n",
    "    print(f\"Validation Loss:  {(loss_tot):>0.5f}\")\n",
    "    print(f\"Validation Accuracy: {(100*correct):>0.5f}%\\n\")\n",
    "    current_max_val_acc = max(current_max_val_acc,100*correct)\n",
    "    print(f\"Current Best Validation Accuracy: {(current_max_val_acc):>0.5f}%\\n\")\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77Hw6rVlvS8U",
   "metadata": {
    "id": "77Hw6rVlvS8U"
   },
   "outputs": [],
   "source": [
    "class XRayToothDataset(Dataset):\n",
    "    def __init__(self, cwd, img_dir, transform=None, target_height=None, target_width=None):\n",
    "        self.dataset_path = cwd + '/' + img_dir\n",
    "        self.transform = transform\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dataset_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx  >= len(os.listdir(self.dataset_path)):\n",
    "            print(\"No datafile/image at index : \"+ str(idx))\n",
    "            return None\n",
    "        img_filename = os.listdir(self.dataset_path)[idx]\n",
    "        age = float(img_filename.split(\"_\")[1][:-4])\n",
    "        age_gt = get_ground_truth(age)\n",
    "        image_tensor = read_image(path=self.dataset_path + '/' + img_filename)\n",
    "        image_tensor = image_tensor.reshape(1, 3, image_tensor.shape[-2], image_tensor.shape[-1])\n",
    "        if self.target_height and self.target_width: # Resize the image \n",
    "            image_tensor = torch.nn.functional.interpolate(image_tensor, (self.target_height,self.target_width))\n",
    "        if self.transform: image_tensor = self.transform(image_tensor) # Apply transformations\n",
    "        image_tensor = (image_tensor-image_tensor.min())/(image_tensor.max()-image_tensor.min())\n",
    "        return image_tensor.reshape(-1,image_tensor.shape[-2],image_tensor.shape[-1]).to(torch.float32), torch.tensor(age_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "AHwUHW0XvX0s",
   "metadata": {
    "id": "AHwUHW0XvX0s"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation Transformations \n",
    "data_augmentation_transformations = T.RandomChoice([\n",
    "    T.RandomAffine(degrees=0), # No Augmentation\n",
    "    T.Lambda(lambda x: TF.hflip(img=x)) # Horizontal Flip\n",
    "\n",
    "    # Geometric Transformations:\n",
    "    # T.RandomAffine(degrees=0, scale=(1.3,1.3)), # Scale\n",
    "    # T.RandomAffine(degrees=0, translate=(0.5,0.5)), # Translate\n",
    "    # T.RandomAffine(degrees=(-8, 8)), # Rotate\n",
    "    # T.Lambda(lambda x: TF.hflip(img=x)), # Reflect\n",
    "\n",
    "    # Occlusion:\n",
    "    # T.Compose([T.RandomErasing(p=1, scale=(0.0008, 0.0008), ratio=(1,1))]*100), # Occlusion\n",
    "\n",
    "    # Intensity Operations\n",
    "    # T.Lambda(lambda x: TF.adjust_gamma(img=x, gamma=0.5)), # Gamma Contrast\n",
    "    # T.Lambda(lambda x: TF.adjust_contrast(x, contrast_factor=2.0)), # Linear Contrast\n",
    "\n",
    "    # Filtering:\n",
    "    # T.Lambda(lambda x: TF.adjust_sharpness(img=x, sharpness_factor=4)), #Sharpen\n",
    "    # T.GaussianBlur(kernel_size=(15,15), sigma=(0.01, 1)), # Gaussian Blur\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "GcLfF0ubvjzD",
   "metadata": {
    "id": "GcLfF0ubvjzD"
   },
   "outputs": [],
   "source": [
    "training_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/training', transform=data_augmentation_transformations, target_height=384, target_width=384)\n",
    "validation_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/validation', transform=None, target_height=384, target_width=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9oKNGV8z4mug",
   "metadata": {
    "id": "9oKNGV8z4mug"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "pretrained_resnet = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n",
    "\n",
    "for param in pretrained_resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tRfaW-WK4pl3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRfaW-WK4pl3",
    "outputId": "1c039185-1613-404c-9980-46824dadfca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 192, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
      "              ReLU-3         [-1, 64, 192, 192]               0\n",
      "         MaxPool2d-4           [-1, 64, 96, 96]               0\n",
      "            Conv2d-5           [-1, 64, 96, 96]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 96, 96]             128\n",
      "              ReLU-7           [-1, 64, 96, 96]               0\n",
      "            Conv2d-8           [-1, 64, 96, 96]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 96, 96]             128\n",
      "             ReLU-10           [-1, 64, 96, 96]               0\n",
      "           Conv2d-11          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 96, 96]             512\n",
      "           Conv2d-13          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 96, 96]             512\n",
      "             ReLU-15          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-16          [-1, 256, 96, 96]               0\n",
      "           Conv2d-17           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 96, 96]             128\n",
      "             ReLU-19           [-1, 64, 96, 96]               0\n",
      "           Conv2d-20           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 96, 96]             128\n",
      "             ReLU-22           [-1, 64, 96, 96]               0\n",
      "           Conv2d-23          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 96, 96]             512\n",
      "             ReLU-25          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-26          [-1, 256, 96, 96]               0\n",
      "           Conv2d-27           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 96, 96]             128\n",
      "             ReLU-29           [-1, 64, 96, 96]               0\n",
      "           Conv2d-30           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 96, 96]             128\n",
      "             ReLU-32           [-1, 64, 96, 96]               0\n",
      "           Conv2d-33          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 96, 96]             512\n",
      "             ReLU-35          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-36          [-1, 256, 96, 96]               0\n",
      "           Conv2d-37          [-1, 128, 96, 96]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 96, 96]             256\n",
      "             ReLU-39          [-1, 128, 96, 96]               0\n",
      "           Conv2d-40          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 48, 48]             256\n",
      "             ReLU-42          [-1, 128, 48, 48]               0\n",
      "           Conv2d-43          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 48, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 48, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 48, 48]               0\n",
      "           Conv2d-49          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 48, 48]             256\n",
      "             ReLU-51          [-1, 128, 48, 48]               0\n",
      "           Conv2d-52          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 48, 48]             256\n",
      "             ReLU-54          [-1, 128, 48, 48]               0\n",
      "           Conv2d-55          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 48, 48]               0\n",
      "           Conv2d-59          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 48, 48]             256\n",
      "             ReLU-61          [-1, 128, 48, 48]               0\n",
      "           Conv2d-62          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 48, 48]             256\n",
      "             ReLU-64          [-1, 128, 48, 48]               0\n",
      "           Conv2d-65          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 48, 48]               0\n",
      "           Conv2d-69          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 48, 48]             256\n",
      "             ReLU-71          [-1, 128, 48, 48]               0\n",
      "           Conv2d-72          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 48, 48]             256\n",
      "             ReLU-74          [-1, 128, 48, 48]               0\n",
      "           Conv2d-75          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 48, 48]               0\n",
      "           Conv2d-79          [-1, 256, 48, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 48, 48]             512\n",
      "             ReLU-81          [-1, 256, 48, 48]               0\n",
      "           Conv2d-82          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 24, 24]             512\n",
      "             ReLU-84          [-1, 256, 24, 24]               0\n",
      "           Conv2d-85         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 24, 24]           2,048\n",
      "           Conv2d-87         [-1, 1024, 24, 24]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-89         [-1, 1024, 24, 24]               0\n",
      "       Bottleneck-90         [-1, 1024, 24, 24]               0\n",
      "           Conv2d-91          [-1, 256, 24, 24]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 24, 24]             512\n",
      "             ReLU-93          [-1, 256, 24, 24]               0\n",
      "           Conv2d-94          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 24, 24]             512\n",
      "             ReLU-96          [-1, 256, 24, 24]               0\n",
      "           Conv2d-97         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-99         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-100         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-101          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 24, 24]             512\n",
      "            ReLU-103          [-1, 256, 24, 24]               0\n",
      "          Conv2d-104          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 24, 24]             512\n",
      "            ReLU-106          [-1, 256, 24, 24]               0\n",
      "          Conv2d-107         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-109         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-110         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-111          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 24, 24]             512\n",
      "            ReLU-113          [-1, 256, 24, 24]               0\n",
      "          Conv2d-114          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 24, 24]             512\n",
      "            ReLU-116          [-1, 256, 24, 24]               0\n",
      "          Conv2d-117         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-119         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-120         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-121          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 24, 24]             512\n",
      "            ReLU-123          [-1, 256, 24, 24]               0\n",
      "          Conv2d-124          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 24, 24]             512\n",
      "            ReLU-126          [-1, 256, 24, 24]               0\n",
      "          Conv2d-127         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-129         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-130         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-131          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 24, 24]             512\n",
      "            ReLU-133          [-1, 256, 24, 24]               0\n",
      "          Conv2d-134          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 24, 24]             512\n",
      "            ReLU-136          [-1, 256, 24, 24]               0\n",
      "          Conv2d-137         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-139         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-140         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-141          [-1, 512, 24, 24]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 24, 24]           1,024\n",
      "            ReLU-143          [-1, 512, 24, 24]               0\n",
      "          Conv2d-144          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-146          [-1, 512, 12, 12]               0\n",
      "          Conv2d-147         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 12, 12]           4,096\n",
      "          Conv2d-149         [-1, 2048, 12, 12]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-151         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-152         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-153          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-155          [-1, 512, 12, 12]               0\n",
      "          Conv2d-156          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-158          [-1, 512, 12, 12]               0\n",
      "          Conv2d-159         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-161         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-162         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-163          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-165          [-1, 512, 12, 12]               0\n",
      "          Conv2d-166          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-168          [-1, 512, 12, 12]               0\n",
      "          Conv2d-169         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-171         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-172         [-1, 2048, 12, 12]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,557,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 842.09\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 941.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(pretrained_resnet, (3,384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7_GafBd2vsM0",
   "metadata": {
    "id": "7_GafBd2vsM0"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = pretrained_resnet \n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1000,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,256),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Xjq02ujSgi2K",
   "metadata": {
    "id": "Xjq02ujSgi2K"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ZlDTNXFOnVrR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlDTNXFOnVrR",
    "outputId": "f03b13ab-f5ca-4926-b8e1-678ef851fb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 192, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
      "              ReLU-3         [-1, 64, 192, 192]               0\n",
      "         MaxPool2d-4           [-1, 64, 96, 96]               0\n",
      "            Conv2d-5           [-1, 64, 96, 96]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 96, 96]             128\n",
      "              ReLU-7           [-1, 64, 96, 96]               0\n",
      "            Conv2d-8           [-1, 64, 96, 96]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 96, 96]             128\n",
      "             ReLU-10           [-1, 64, 96, 96]               0\n",
      "           Conv2d-11          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 96, 96]             512\n",
      "           Conv2d-13          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 96, 96]             512\n",
      "             ReLU-15          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-16          [-1, 256, 96, 96]               0\n",
      "           Conv2d-17           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 96, 96]             128\n",
      "             ReLU-19           [-1, 64, 96, 96]               0\n",
      "           Conv2d-20           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 96, 96]             128\n",
      "             ReLU-22           [-1, 64, 96, 96]               0\n",
      "           Conv2d-23          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 96, 96]             512\n",
      "             ReLU-25          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-26          [-1, 256, 96, 96]               0\n",
      "           Conv2d-27           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 96, 96]             128\n",
      "             ReLU-29           [-1, 64, 96, 96]               0\n",
      "           Conv2d-30           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 96, 96]             128\n",
      "             ReLU-32           [-1, 64, 96, 96]               0\n",
      "           Conv2d-33          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 96, 96]             512\n",
      "             ReLU-35          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-36          [-1, 256, 96, 96]               0\n",
      "           Conv2d-37          [-1, 128, 96, 96]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 96, 96]             256\n",
      "             ReLU-39          [-1, 128, 96, 96]               0\n",
      "           Conv2d-40          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 48, 48]             256\n",
      "             ReLU-42          [-1, 128, 48, 48]               0\n",
      "           Conv2d-43          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 48, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 48, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 48, 48]               0\n",
      "           Conv2d-49          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 48, 48]             256\n",
      "             ReLU-51          [-1, 128, 48, 48]               0\n",
      "           Conv2d-52          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 48, 48]             256\n",
      "             ReLU-54          [-1, 128, 48, 48]               0\n",
      "           Conv2d-55          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 48, 48]               0\n",
      "           Conv2d-59          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 48, 48]             256\n",
      "             ReLU-61          [-1, 128, 48, 48]               0\n",
      "           Conv2d-62          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 48, 48]             256\n",
      "             ReLU-64          [-1, 128, 48, 48]               0\n",
      "           Conv2d-65          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 48, 48]               0\n",
      "           Conv2d-69          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 48, 48]             256\n",
      "             ReLU-71          [-1, 128, 48, 48]               0\n",
      "           Conv2d-72          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 48, 48]             256\n",
      "             ReLU-74          [-1, 128, 48, 48]               0\n",
      "           Conv2d-75          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 48, 48]               0\n",
      "           Conv2d-79          [-1, 256, 48, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 48, 48]             512\n",
      "             ReLU-81          [-1, 256, 48, 48]               0\n",
      "           Conv2d-82          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 24, 24]             512\n",
      "             ReLU-84          [-1, 256, 24, 24]               0\n",
      "           Conv2d-85         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 24, 24]           2,048\n",
      "           Conv2d-87         [-1, 1024, 24, 24]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-89         [-1, 1024, 24, 24]               0\n",
      "       Bottleneck-90         [-1, 1024, 24, 24]               0\n",
      "           Conv2d-91          [-1, 256, 24, 24]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 24, 24]             512\n",
      "             ReLU-93          [-1, 256, 24, 24]               0\n",
      "           Conv2d-94          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 24, 24]             512\n",
      "             ReLU-96          [-1, 256, 24, 24]               0\n",
      "           Conv2d-97         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-99         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-100         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-101          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 24, 24]             512\n",
      "            ReLU-103          [-1, 256, 24, 24]               0\n",
      "          Conv2d-104          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 24, 24]             512\n",
      "            ReLU-106          [-1, 256, 24, 24]               0\n",
      "          Conv2d-107         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-109         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-110         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-111          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 24, 24]             512\n",
      "            ReLU-113          [-1, 256, 24, 24]               0\n",
      "          Conv2d-114          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 24, 24]             512\n",
      "            ReLU-116          [-1, 256, 24, 24]               0\n",
      "          Conv2d-117         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-119         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-120         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-121          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 24, 24]             512\n",
      "            ReLU-123          [-1, 256, 24, 24]               0\n",
      "          Conv2d-124          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 24, 24]             512\n",
      "            ReLU-126          [-1, 256, 24, 24]               0\n",
      "          Conv2d-127         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-129         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-130         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-131          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 24, 24]             512\n",
      "            ReLU-133          [-1, 256, 24, 24]               0\n",
      "          Conv2d-134          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 24, 24]             512\n",
      "            ReLU-136          [-1, 256, 24, 24]               0\n",
      "          Conv2d-137         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-139         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-140         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-141          [-1, 512, 24, 24]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 24, 24]           1,024\n",
      "            ReLU-143          [-1, 512, 24, 24]               0\n",
      "          Conv2d-144          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-146          [-1, 512, 12, 12]               0\n",
      "          Conv2d-147         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 12, 12]           4,096\n",
      "          Conv2d-149         [-1, 2048, 12, 12]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-151         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-152         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-153          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-155          [-1, 512, 12, 12]               0\n",
      "          Conv2d-156          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-158          [-1, 512, 12, 12]               0\n",
      "          Conv2d-159         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-161         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-162         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-163          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-165          [-1, 512, 12, 12]               0\n",
      "          Conv2d-166          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-168          [-1, 512, 12, 12]               0\n",
      "          Conv2d-169         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-171         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-172         [-1, 2048, 12, 12]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "          ResNet-175                 [-1, 1000]               0\n",
      "          Linear-176                  [-1, 512]         512,512\n",
      "            ReLU-177                  [-1, 512]               0\n",
      "         Dropout-178                  [-1, 512]               0\n",
      "          Linear-179                  [-1, 256]         131,328\n",
      "================================================================\n",
      "Total params: 26,200,872\n",
      "Trainable params: 643,840\n",
      "Non-trainable params: 25,557,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 842.11\n",
      "Params size (MB): 99.95\n",
      "Estimated Total Size (MB): 943.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ZzpO5XU0wAmA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzpO5XU0wAmA",
    "outputId": "d51af9b5-7270-44e8-f884-88db8bda0816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1229, -0.0426,  0.0596, -0.1207,  0.0636, -0.0757,  0.0659, -0.0050,\n",
      "          0.0310, -0.0078,  0.0460, -0.0981, -0.0455,  0.1200, -0.0418, -0.2162,\n",
      "         -0.0781,  0.1112, -0.0122,  0.0371,  0.0997, -0.0753,  0.0591, -0.0871,\n",
      "         -0.0941, -0.0969, -0.1495, -0.1043,  0.0178,  0.0270,  0.0322, -0.0395,\n",
      "         -0.0981, -0.0619, -0.0765, -0.0964, -0.0561,  0.0332,  0.0087,  0.0522,\n",
      "         -0.0203,  0.0721,  0.0700, -0.0771,  0.0330, -0.1854,  0.0961,  0.0045,\n",
      "         -0.0541, -0.0705, -0.1029, -0.0333,  0.0539,  0.1482, -0.2207,  0.1004,\n",
      "          0.0488,  0.1257,  0.1020, -0.1247, -0.0869,  0.0556,  0.0331, -0.1125,\n",
      "         -0.0129, -0.1168,  0.0599,  0.1336, -0.0559,  0.0591, -0.0071, -0.0288,\n",
      "          0.0461, -0.0509, -0.0464,  0.1547,  0.1388,  0.1205,  0.1742,  0.0462,\n",
      "         -0.0223,  0.0115,  0.2496, -0.1495, -0.0267, -0.0523,  0.0812,  0.0138,\n",
      "          0.1420, -0.0303, -0.2309, -0.1351,  0.0614, -0.0950,  0.0939, -0.0649,\n",
      "         -0.1391, -0.1525, -0.0585,  0.0083,  0.0426,  0.0786, -0.0661, -0.0061,\n",
      "          0.0219,  0.1673, -0.0433, -0.0087, -0.0984,  0.0276, -0.0401,  0.1404,\n",
      "         -0.0081,  0.0305,  0.0988, -0.1082,  0.1103, -0.0458,  0.0640, -0.0424,\n",
      "          0.1502,  0.0420, -0.0106, -0.0633, -0.0092, -0.0772, -0.0101, -0.0201,\n",
      "         -0.0091,  0.0173,  0.0427, -0.1796, -0.0617, -0.0372, -0.0476,  0.0111,\n",
      "         -0.2540, -0.0977, -0.0303, -0.0722,  0.0344, -0.1701, -0.0618, -0.0094,\n",
      "         -0.0625, -0.1019, -0.0678,  0.1673, -0.1970,  0.1545,  0.0540,  0.0890,\n",
      "         -0.0636, -0.1390, -0.0938, -0.0378, -0.0350,  0.0924, -0.0537, -0.1222,\n",
      "         -0.0599, -0.0214,  0.0412,  0.1545,  0.0354,  0.0891, -0.0282,  0.0119,\n",
      "         -0.1380, -0.1229, -0.0056,  0.0472, -0.1919, -0.0128,  0.0644,  0.0787,\n",
      "         -0.0583,  0.0716, -0.0184,  0.0598, -0.1209,  0.0124,  0.0159,  0.0051,\n",
      "         -0.0158,  0.0008, -0.1624,  0.0111, -0.2362, -0.0467, -0.0755,  0.0942,\n",
      "         -0.0515,  0.1992, -0.0253,  0.0299,  0.1174, -0.0659,  0.0524, -0.1254,\n",
      "         -0.0410, -0.1028,  0.1197, -0.0659,  0.0064, -0.0018, -0.0556,  0.0516,\n",
      "         -0.0613, -0.1031, -0.0039, -0.0227, -0.0858,  0.0953, -0.0957, -0.2246,\n",
      "         -0.0788,  0.0483, -0.0236, -0.0165,  0.1198, -0.1822,  0.0237, -0.0102,\n",
      "          0.0317, -0.0396,  0.0426, -0.0129,  0.1533,  0.1555, -0.0728, -0.1724,\n",
      "         -0.0608,  0.0498, -0.1343,  0.0017, -0.0669, -0.0340, -0.0757,  0.0994,\n",
      "          0.0487, -0.0028,  0.0392,  0.0221,  0.0075, -0.1299, -0.0391,  0.1667,\n",
      "         -0.0520,  0.0947,  0.1950,  0.1416, -0.0022, -0.0629,  0.1220, -0.1068]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test a forward pass\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    data = training_data[0][0].reshape(-1,3,384,384).to(device)\n",
    "    label = training_data[0][1].reshape(-1,6).to(device)\n",
    "    embed = model(data)\n",
    "    print(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "Xy5dsAcpwCri",
   "metadata": {
    "id": "Xy5dsAcpwCri"
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "learning_rate = 1e-2\n",
    "margin_loss_learning_rate = 9e-1\n",
    "momentum=0.9\n",
    "weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "WhovjcHqwX91",
   "metadata": {
    "id": "WhovjcHqwX91"
   },
   "outputs": [],
   "source": [
    "training_data_loader = DataLoader(training_data, batch_size, shuffle = True)\n",
    "validation_data_loader = DataLoader(validation_data, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rknwp8cQ5sQ_",
   "metadata": {
    "id": "rknwp8cQ5sQ_"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "margin_loss_regularizer = regularizers.RegularFaceRegularizer()\n",
    "margin_loss_function = losses.ArcFaceLoss(6, 256, margin=34.3, scale=1, weight_regularizer=margin_loss_regularizer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "YenD-SOUwRAV",
   "metadata": {
    "id": "YenD-SOUwRAV"
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_optimizer = torch.optim.SGD(margin_loss_function.parameters(), lr=margin_loss_learning_rate)\n",
    "\n",
    "# Schedulers\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, min_lr=1e-8,verbose=True)\n",
    "margin_loss_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, min_lr=1e-8,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "s7NVlZBIwh-F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7NVlZBIwh-F",
    "outputId": "0f3432a0-8b59-4e6f-9b70-3aab60968552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "training loss: 6.43083\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  4.05144\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "training loss: 5.85831\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  4.04207\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "training loss: 5.76291\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  4.07209\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "training loss: 5.69359\n",
      "Correct/Total: 56/129\n",
      "Validation Loss:  4.11844\n",
      "Validation Accuracy: 43.41085%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "training loss: 5.63454\n",
      "Correct/Total: 28/129\n",
      "Validation Loss:  4.15935\n",
      "Validation Accuracy: 21.70543%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "training loss: 5.54904\n",
      "Correct/Total: 28/129\n",
      "Validation Loss:  4.18799\n",
      "Validation Accuracy: 21.70543%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "training loss: 5.50192\n",
      "Correct/Total: 28/129\n",
      "Validation Loss:  4.21137\n",
      "Validation Accuracy: 21.70543%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "training loss: 5.45367\n",
      "Correct/Total: 28/129\n",
      "Validation Loss:  4.22660\n",
      "Validation Accuracy: 21.70543%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "training loss: 5.35401\n",
      "Correct/Total: 32/129\n",
      "Validation Loss:  4.19553\n",
      "Validation Accuracy: 24.80620%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "training loss: 5.29217\n",
      "Correct/Total: 34/129\n",
      "Validation Loss:  4.11186\n",
      "Validation Accuracy: 26.35659%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "training loss: 5.17813\n",
      "Correct/Total: 33/129\n",
      "Validation Loss:  4.07629\n",
      "Validation Accuracy: 25.58140%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "training loss: 5.03711\n",
      "Correct/Total: 40/129\n",
      "Validation Loss:  4.04063\n",
      "Validation Accuracy: 31.00775%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "training loss: 5.00385\n",
      "Correct/Total: 41/129\n",
      "Validation Loss:  4.07784\n",
      "Validation Accuracy: 31.78295%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "training loss: 4.88035\n",
      "Correct/Total: 41/129\n",
      "Validation Loss:  4.11058\n",
      "Validation Accuracy: 31.78295%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "training loss: 4.79121\n",
      "Correct/Total: 47/129\n",
      "Validation Loss:  4.19028\n",
      "Validation Accuracy: 36.43411%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "training loss: 4.73736\n",
      "Correct/Total: 52/129\n",
      "Validation Loss:  4.20964\n",
      "Validation Accuracy: 40.31008%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "training loss: 4.67760\n",
      "Correct/Total: 52/129\n",
      "Validation Loss:  4.30436\n",
      "Validation Accuracy: 40.31008%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "training loss: 4.54053\n",
      "Correct/Total: 47/129\n",
      "Validation Loss:  4.36791\n",
      "Validation Accuracy: 36.43411%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "training loss: 4.44554\n",
      "Correct/Total: 46/129\n",
      "Validation Loss:  4.42094\n",
      "Validation Accuracy: 35.65891%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "training loss: 4.39639\n",
      "Correct/Total: 37/129\n",
      "Validation Loss:  4.46478\n",
      "Validation Accuracy: 28.68217%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "training loss: 4.30416\n",
      "Correct/Total: 28/129\n",
      "Validation Loss:  4.56163\n",
      "Validation Accuracy: 21.70543%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "training loss: 4.25754\n",
      "Correct/Total: 23/129\n",
      "Validation Loss:  4.59269\n",
      "Validation Accuracy: 17.82946%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "training loss: 4.20661\n",
      "Correct/Total: 24/129\n",
      "Validation Loss:  4.52032\n",
      "Validation Accuracy: 18.60465%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "training loss: 4.10653\n",
      "Correct/Total: 35/129\n",
      "Validation Loss:  4.34660\n",
      "Validation Accuracy: 27.13178%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "training loss: 4.03857\n",
      "Correct/Total: 41/129\n",
      "Validation Loss:  4.31863\n",
      "Validation Accuracy: 31.78295%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "training loss: 3.93614\n",
      "Correct/Total: 47/129\n",
      "Validation Loss:  4.29125\n",
      "Validation Accuracy: 36.43411%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "training loss: 3.91532\n",
      "Correct/Total: 49/129\n",
      "Validation Loss:  4.30248\n",
      "Validation Accuracy: 37.98450%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "training loss: 3.87276\n",
      "Correct/Total: 56/129\n",
      "Validation Loss:  4.01526\n",
      "Validation Accuracy: 43.41085%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "training loss: 3.82990\n",
      "Correct/Total: 66/129\n",
      "Validation Loss:  3.80307\n",
      "Validation Accuracy: 51.16279%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "training loss: 3.77755\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.72678\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "training loss: 3.76090\n",
      "Correct/Total: 71/129\n",
      "Validation Loss:  3.66490\n",
      "Validation Accuracy: 55.03876%\n",
      "\n",
      "Current Best Validation Accuracy: 55.03876%\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "training loss: 3.71664\n",
      "Correct/Total: 79/129\n",
      "Validation Loss:  3.55890\n",
      "Validation Accuracy: 61.24031%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "training loss: 3.68105\n",
      "Correct/Total: 79/129\n",
      "Validation Loss:  3.47050\n",
      "Validation Accuracy: 61.24031%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "training loss: 3.63437\n",
      "Correct/Total: 78/129\n",
      "Validation Loss:  3.47818\n",
      "Validation Accuracy: 60.46512%\n",
      "\n",
      "Current Best Validation Accuracy: 61.24031%\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "training loss: 3.61384\n",
      "Correct/Total: 81/129\n",
      "Validation Loss:  3.43990\n",
      "Validation Accuracy: 62.79070%\n",
      "\n",
      "Current Best Validation Accuracy: 62.79070%\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "training loss: 3.62501\n",
      "Correct/Total: 84/129\n",
      "Validation Loss:  3.42965\n",
      "Validation Accuracy: 65.11628%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "training loss: 3.55539\n",
      "Correct/Total: 83/129\n",
      "Validation Loss:  3.46322\n",
      "Validation Accuracy: 64.34109%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "training loss: 3.54070\n",
      "Correct/Total: 83/129\n",
      "Validation Loss:  3.46480\n",
      "Validation Accuracy: 64.34109%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "training loss: 3.52573\n",
      "Correct/Total: 79/129\n",
      "Validation Loss:  3.46635\n",
      "Validation Accuracy: 61.24031%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "training loss: 3.48112\n",
      "Correct/Total: 78/129\n",
      "Validation Loss:  3.48553\n",
      "Validation Accuracy: 60.46512%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "training loss: 3.47756\n",
      "Correct/Total: 75/129\n",
      "Validation Loss:  3.48379\n",
      "Validation Accuracy: 58.13953%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "training loss: 3.40658\n",
      "Correct/Total: 75/129\n",
      "Validation Loss:  3.45440\n",
      "Validation Accuracy: 58.13953%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "training loss: 3.39395\n",
      "Correct/Total: 78/129\n",
      "Validation Loss:  3.42460\n",
      "Validation Accuracy: 60.46512%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "training loss: 3.39635\n",
      "Correct/Total: 80/129\n",
      "Validation Loss:  3.43491\n",
      "Validation Accuracy: 62.01550%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "training loss: 3.38121\n",
      "Correct/Total: 77/129\n",
      "Validation Loss:  3.46311\n",
      "Validation Accuracy: 59.68992%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "training loss: 3.38676\n",
      "Correct/Total: 78/129\n",
      "Validation Loss:  3.45656\n",
      "Validation Accuracy: 60.46512%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "training loss: 3.33603\n",
      "Correct/Total: 72/129\n",
      "Validation Loss:  3.42394\n",
      "Validation Accuracy: 55.81395%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "training loss: 3.32128\n",
      "Correct/Total: 76/129\n",
      "Validation Loss:  3.39784\n",
      "Validation Accuracy: 58.91473%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "training loss: 3.35064\n",
      "Correct/Total: 82/129\n",
      "Validation Loss:  3.39975\n",
      "Validation Accuracy: 63.56589%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "training loss: 3.30177\n",
      "Correct/Total: 81/129\n",
      "Validation Loss:  3.36908\n",
      "Validation Accuracy: 62.79070%\n",
      "\n",
      "Current Best Validation Accuracy: 65.11628%\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(training_data_loader, model, optimizer, margin_loss_function, loss_optimizer)\n",
    "    val_loss = validation(validation_data_loader, model, margin_loss_function)\n",
    "    # scheduler.step(val_loss)\n",
    "    # margin_loss_scheduler.step(val_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ftmlVBNj5yCw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ftmlVBNj5yCw",
    "outputId": "f35ee72d-e52b-4e05-82d6-791222c1de6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f42fcda0cd0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2CfBxLx3ITSu",
   "metadata": {
    "id": "2CfBxLx3ITSu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
