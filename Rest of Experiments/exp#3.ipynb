{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kgTCEDXzibaZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgTCEDXzibaZ",
    "outputId": "68756066-1bb5-45ff-c133-1f6ad6da873c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdHENHQJkaNa",
   "metadata": {
    "id": "bdHENHQJkaNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "import getpass\n",
    "import math\n",
    "import numpy\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image,ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6C9vAiat-6F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6C9vAiat-6F",
    "outputId": "bbe3b952-1d83-417d-db59-342f249b8a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0f39d99010>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "OxcfShJ_uDVs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxcfShJ_uDVs",
    "outputId": "795f1ca6-aad2-46f1-ed18-18ed525daefe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ZTOkACl6d2s5",
   "metadata": {
    "id": "ZTOkACl6d2s5"
   },
   "outputs": [],
   "source": [
    "dataset_save_dir = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdA042w3vQUk",
   "metadata": {
    "id": "fdA042w3vQUk"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(val):\n",
    "    arr = numpy.zeros((6,), dtype=int)\n",
    "    arr[val] = 1\n",
    "    return arr\n",
    "\n",
    "def get_bucket_id(age):\n",
    "  age_floor = int(age)\n",
    "  if age_floor >= 0 and age_floor <= 5: return 0\n",
    "  elif age_floor >= 6 and age_floor <= 12: return 1\n",
    "  elif age_floor >= 13 and age_floor <= 19: return 2\n",
    "  elif age_floor >= 20 and age_floor <= 29: return 3\n",
    "  elif age_floor >= 30 and age_floor <= 59: return 4\n",
    "  else: return 5\n",
    "\n",
    "def get_ground_truth(age):\n",
    "  return one_hot_encode(get_bucket_id(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uVNdhyjdwbMM",
   "metadata": {
    "id": "uVNdhyjdwbMM"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_function, loss_optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Zeroing the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss_optimizer.zero_grad()\n",
    "\n",
    "        # Get Embeddings\n",
    "        embeddings = model(X)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(embeddings, y.argmax(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        loss_optimizer.step()\n",
    "\n",
    "        loss_tot += loss.item()\n",
    "        num += 1\n",
    "        \n",
    "        X.cpu()\n",
    "        y.cpu()\n",
    "\n",
    "    # loss_tot /= num\n",
    "    print(f'training loss: {(loss_tot):>0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "I9iNr-rLwdAb",
   "metadata": {
    "id": "I9iNr-rLwdAb"
   },
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "current_max_val_acc = 0.0\n",
    "def validation(dataloader, model, loss_function):\n",
    "    global current_max_val_acc\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    totalsize = 0\n",
    "    loss_tot = 0.0\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward With Logits\n",
    "            embeddings = model(X)        \n",
    "            logits = loss_function.get_logits(embeddings)\n",
    "            predSoftmax = nn.Softmax(dim=1)(logits)\n",
    "            loss = loss_function(embeddings,y.argmax(1))\n",
    "            \n",
    "            correct += (predSoftmax.argmax(1) == y.argmax(1)).sum().item()\n",
    "            totalsize += predSoftmax.shape[0]\n",
    "            loss_tot += loss.item()\n",
    "            num += 1\n",
    "            X.cpu()\n",
    "            y.cpu()\n",
    "            \n",
    "    print(f\"Correct/Total: {correct}/{totalsize}\")\n",
    "    correct /= totalsize\n",
    "    validation_accuracy.append(correct*100)\n",
    "    print(f\"Validation Loss:  {(loss_tot):>0.5f}\")\n",
    "    print(f\"Validation Accuracy: {(100*correct):>0.5f}%\\n\")\n",
    "    current_max_val_acc = max(current_max_val_acc,100*correct)\n",
    "    print(f\"Current Best Validation Accuracy: {(current_max_val_acc):>0.5f}%\\n\")\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77Hw6rVlvS8U",
   "metadata": {
    "id": "77Hw6rVlvS8U"
   },
   "outputs": [],
   "source": [
    "class XRayToothDataset(Dataset):\n",
    "    def __init__(self, cwd, img_dir, transform=None, target_height=None, target_width=None):\n",
    "        self.dataset_path = cwd + '/' + img_dir\n",
    "        self.transform = transform\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dataset_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx  >= len(os.listdir(self.dataset_path)):\n",
    "            print(\"No datafile/image at index : \"+ str(idx))\n",
    "            return None\n",
    "        img_filename = os.listdir(self.dataset_path)[idx]\n",
    "        age = float(img_filename.split(\"_\")[1][:-4])\n",
    "        age_gt = get_ground_truth(age)\n",
    "        image_tensor = read_image(path=self.dataset_path + '/' + img_filename)\n",
    "        image_tensor = image_tensor.reshape(1, 3, image_tensor.shape[-2], image_tensor.shape[-1])\n",
    "        if self.target_height and self.target_width: # Resize the image \n",
    "            image_tensor = torch.nn.functional.interpolate(image_tensor, (self.target_height,self.target_width))\n",
    "        if self.transform: image_tensor = self.transform(image_tensor) # Apply transformations\n",
    "        image_tensor = (image_tensor-image_tensor.min())/(image_tensor.max()-image_tensor.min())\n",
    "        return image_tensor.reshape(-1,image_tensor.shape[-2],image_tensor.shape[-1]).to(torch.float32), torch.tensor(age_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "AHwUHW0XvX0s",
   "metadata": {
    "id": "AHwUHW0XvX0s"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation Transformations \n",
    "data_augmentation_transformations = T.RandomChoice([\n",
    "    T.RandomAffine(degrees=0), # No Augmentation\n",
    "    T.Lambda(lambda x: TF.hflip(img=x)) # Horizontal Flip\n",
    "\n",
    "    # Geometric Transformations:\n",
    "    # T.RandomAffine(degrees=0, scale=(1.3,1.3)), # Scale\n",
    "    # T.RandomAffine(degrees=0, translate=(0.5,0.5)), # Translate\n",
    "    # T.RandomAffine(degrees=(-8, 8)), # Rotate\n",
    "    # T.Lambda(lambda x: TF.hflip(img=x)), # Reflect\n",
    "\n",
    "    # Occlusion:\n",
    "    # T.Compose([T.RandomErasing(p=1, scale=(0.0008, 0.0008), ratio=(1,1))]*100), # Occlusion\n",
    "\n",
    "    # Intensity Operations\n",
    "    # T.Lambda(lambda x: TF.adjust_gamma(img=x, gamma=0.5)), # Gamma Contrast\n",
    "    # T.Lambda(lambda x: TF.adjust_contrast(x, contrast_factor=2.0)), # Linear Contrast\n",
    "\n",
    "    # Filtering:\n",
    "    # T.Lambda(lambda x: TF.adjust_sharpness(img=x, sharpness_factor=4)), #Sharpen\n",
    "    # T.GaussianBlur(kernel_size=(15,15), sigma=(0.01, 1)), # Gaussian Blur\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "GcLfF0ubvjzD",
   "metadata": {
    "id": "GcLfF0ubvjzD"
   },
   "outputs": [],
   "source": [
    "training_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/training', transform=data_augmentation_transformations, target_height=384, target_width=384)\n",
    "validation_data = XRayToothDataset(os.getcwd(), img_dir=dataset_save_dir+'/validation', transform=None, target_height=384, target_width=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7_GafBd2vsM0",
   "metadata": {
    "id": "7_GafBd2vsM0"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=280, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2520,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,512)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Xjq02ujSgi2K",
   "metadata": {
    "id": "Xjq02ujSgi2K"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ZlDTNXFOnVrR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlDTNXFOnVrR",
    "outputId": "42d3f23f-7880-4ae1-f1bd-80b336366e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 383, 383]             416\n",
      "              ReLU-2         [-1, 32, 383, 383]               0\n",
      "         MaxPool2d-3         [-1, 32, 127, 127]               0\n",
      "            Conv2d-4         [-1, 64, 126, 126]           8,256\n",
      "              ReLU-5         [-1, 64, 126, 126]               0\n",
      "         MaxPool2d-6           [-1, 64, 42, 42]               0\n",
      "            Conv2d-7          [-1, 128, 41, 41]          32,896\n",
      "              ReLU-8          [-1, 128, 41, 41]               0\n",
      "         MaxPool2d-9          [-1, 128, 13, 13]               0\n",
      "           Conv2d-10          [-1, 256, 12, 12]         131,328\n",
      "             ReLU-11          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-12            [-1, 256, 4, 4]               0\n",
      "           Conv2d-13            [-1, 280, 3, 3]         287,000\n",
      "             ReLU-14            [-1, 280, 3, 3]               0\n",
      "          Flatten-15                 [-1, 2520]               0\n",
      "           Linear-16                 [-1, 1024]       2,581,504\n",
      "             ReLU-17                 [-1, 1024]               0\n",
      "           Linear-18                  [-1, 512]         524,800\n",
      "================================================================\n",
      "Total params: 3,566,200\n",
      "Trainable params: 3,566,200\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 96.05\n",
      "Params size (MB): 13.60\n",
      "Estimated Total Size (MB): 111.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ZzpO5XU0wAmA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzpO5XU0wAmA",
    "outputId": "baf38630-454b-43e8-c123-152a6dac09fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4981e-02,  1.0995e-02, -2.3925e-02, -1.3316e-03, -2.2172e-02,\n",
      "         -2.4104e-02, -2.9600e-02,  5.2513e-03,  7.5408e-03, -1.3752e-02,\n",
      "          4.8989e-04,  4.5686e-02, -1.7035e-03,  6.2442e-03,  1.8329e-02,\n",
      "          5.0660e-02,  6.4145e-03,  1.0992e-03, -1.7290e-02, -3.1199e-02,\n",
      "          2.0574e-02,  3.2510e-02, -1.6959e-02,  1.5877e-02, -1.0236e-02,\n",
      "          7.3419e-03,  1.3815e-02,  1.7355e-02, -2.9637e-03, -6.7780e-03,\n",
      "         -9.3905e-03, -6.9001e-03, -1.6044e-02,  4.7284e-03, -6.3638e-03,\n",
      "          3.3319e-02, -1.1262e-02,  3.0464e-02, -2.6038e-02,  2.2370e-02,\n",
      "         -9.9354e-03,  2.2141e-02,  2.3058e-02, -1.7059e-02,  2.6607e-02,\n",
      "         -2.8548e-02, -7.6964e-03,  5.6386e-03,  9.3916e-03,  6.8018e-03,\n",
      "          2.5219e-02, -3.5884e-02,  1.7105e-03, -1.4890e-03, -8.5228e-03,\n",
      "         -2.2192e-02,  8.3172e-03,  2.8158e-02, -2.4753e-02, -5.3097e-03,\n",
      "          6.2231e-03, -2.1612e-02, -1.9070e-02,  1.0484e-02,  9.4734e-03,\n",
      "         -1.1675e-02, -3.3699e-02,  1.0206e-02, -1.0453e-02, -4.3984e-03,\n",
      "          9.7528e-03, -1.4384e-03,  5.9177e-03,  5.5754e-03, -6.8939e-03,\n",
      "         -1.3153e-02,  1.0540e-02, -8.2478e-03, -2.0360e-02, -1.8366e-03,\n",
      "          2.2902e-02, -5.8539e-03, -5.9676e-03,  1.3798e-02,  2.7716e-02,\n",
      "         -7.9154e-03,  2.1439e-02, -1.0390e-02, -2.3595e-02, -4.0461e-02,\n",
      "         -3.1635e-02, -1.2598e-02,  2.9804e-02, -7.1341e-04, -1.6567e-02,\n",
      "          2.6977e-02, -2.9472e-03,  3.2109e-02,  1.7303e-02,  1.4993e-02,\n",
      "         -3.5668e-02,  2.8891e-02,  5.9998e-03,  2.0717e-02,  1.2944e-02,\n",
      "         -1.1749e-02,  2.3243e-02,  2.6787e-02,  7.2810e-03,  3.3518e-03,\n",
      "         -5.3417e-03,  1.8277e-02,  1.7144e-02,  1.3759e-03,  9.1262e-03,\n",
      "         -1.8261e-02, -7.4557e-03, -7.6962e-03,  2.1003e-02, -1.3119e-02,\n",
      "          1.8364e-02, -1.6197e-02, -2.6562e-03, -1.5459e-02, -2.2615e-02,\n",
      "         -1.2714e-02,  2.7933e-02,  1.2451e-02, -3.3951e-02,  6.7322e-03,\n",
      "         -2.4395e-02,  2.4300e-02, -1.3065e-02, -2.2233e-02, -3.2770e-02,\n",
      "          1.3730e-02, -1.6240e-02,  1.3455e-02, -1.6825e-02,  3.6736e-02,\n",
      "          1.3626e-02,  5.2858e-03, -4.2565e-03,  1.3745e-02, -2.4052e-02,\n",
      "          1.7841e-02,  2.0565e-02,  2.1117e-02,  4.9443e-03,  5.3744e-03,\n",
      "          1.6637e-04, -1.0313e-02,  1.8166e-02, -5.6366e-03, -1.0146e-02,\n",
      "         -1.6044e-02,  6.2712e-03,  2.5208e-02, -2.5159e-04,  1.0251e-02,\n",
      "          9.9021e-03, -3.3632e-02, -7.6699e-03, -2.4997e-02,  1.4402e-03,\n",
      "          2.2509e-02, -2.9487e-02, -2.8961e-02, -9.9442e-03,  1.3729e-02,\n",
      "         -2.9286e-02, -7.9225e-03,  3.0534e-03, -1.4981e-02, -1.3021e-02,\n",
      "         -8.9851e-03, -1.8335e-02,  2.1777e-02, -1.9760e-03,  4.1404e-02,\n",
      "         -4.0930e-03,  7.5478e-03,  1.5023e-02,  1.3776e-02,  9.5722e-03,\n",
      "         -2.8595e-02, -3.2055e-03, -1.5487e-02, -8.9160e-04,  1.6475e-02,\n",
      "         -1.0897e-02,  3.4268e-02, -6.0214e-03, -1.9849e-02, -1.6265e-04,\n",
      "         -6.9034e-03,  3.4223e-03, -2.1648e-02, -2.2932e-04,  1.1038e-02,\n",
      "          2.5519e-02, -9.5255e-04, -3.4242e-02,  3.4760e-03, -2.8937e-03,\n",
      "         -3.2258e-02, -1.8869e-02,  2.0007e-02,  2.6576e-02,  1.8172e-03,\n",
      "         -1.7745e-02, -1.4920e-02,  2.6027e-02,  1.2181e-02,  2.0882e-02,\n",
      "          1.5719e-02,  2.1569e-02, -2.9150e-02, -7.1980e-03,  8.9370e-03,\n",
      "          1.3870e-02, -3.9608e-03, -1.8436e-02,  9.9850e-03, -2.6096e-02,\n",
      "          1.1092e-02, -1.2851e-02,  2.3473e-02,  4.1430e-02, -8.3084e-03,\n",
      "         -6.7051e-03, -1.7766e-02,  5.0809e-03,  8.1944e-03,  1.3918e-03,\n",
      "          1.8943e-02, -7.1601e-03, -2.1888e-02, -2.5673e-02, -1.6082e-02,\n",
      "          7.1738e-03,  2.2603e-02, -9.8520e-03,  2.3750e-02, -2.3126e-02,\n",
      "          2.6632e-02,  8.5009e-03, -2.2706e-02,  1.6058e-02,  2.7276e-02,\n",
      "          1.8331e-03,  5.3595e-03,  8.2480e-03, -2.2609e-02, -1.7442e-02,\n",
      "         -2.8132e-03,  3.3413e-02, -3.1850e-03, -8.2745e-03,  3.0425e-03,\n",
      "         -3.4735e-03, -3.4047e-02, -3.6433e-03,  9.5677e-03, -1.5817e-02,\n",
      "          5.2574e-03,  2.5957e-02, -5.9563e-03,  2.5833e-02, -4.8454e-03,\n",
      "         -9.3055e-03, -1.7169e-02,  1.0175e-02, -1.3032e-03,  2.7568e-02,\n",
      "          7.7526e-03,  2.7063e-02, -5.6836e-03, -3.0045e-03, -7.0799e-03,\n",
      "         -3.2584e-02, -1.6198e-02,  9.1423e-03,  5.0158e-03,  1.8446e-02,\n",
      "         -6.4998e-03,  2.3422e-02, -1.3684e-02,  3.4680e-03,  2.4482e-02,\n",
      "          2.3913e-02,  1.4326e-04, -1.3375e-02, -2.9159e-02, -7.1547e-03,\n",
      "         -8.6553e-03, -9.7960e-03,  2.8509e-03,  2.4265e-02,  3.7758e-02,\n",
      "          3.9533e-03, -1.7679e-02,  7.0967e-03,  1.2321e-02,  1.0341e-02,\n",
      "         -1.6097e-02, -2.0084e-02,  2.8635e-02,  2.1768e-02,  3.4186e-02,\n",
      "          1.4217e-02,  1.8614e-02,  3.0020e-02,  1.0293e-02,  1.1325e-02,\n",
      "          2.6004e-03,  1.5467e-02,  2.1632e-02, -2.2644e-02, -2.0392e-02,\n",
      "          6.7632e-03, -2.7697e-04, -4.1218e-03, -1.9979e-02, -1.1270e-02,\n",
      "         -7.9383e-03, -7.1436e-03, -7.7847e-03,  1.8226e-02, -2.2970e-02,\n",
      "          2.7687e-02, -4.2161e-04,  1.9838e-02,  1.8040e-02,  6.5019e-04,\n",
      "          2.6574e-02,  1.0645e-02, -9.0798e-03, -1.6618e-02,  2.1772e-02,\n",
      "          4.6160e-02, -2.5989e-02,  1.8386e-02, -2.3946e-02, -3.3066e-04,\n",
      "         -5.7854e-03, -1.1632e-02, -2.1462e-02, -1.2040e-02, -2.6830e-02,\n",
      "          8.8777e-03,  3.1556e-02,  7.0914e-03, -6.4823e-04, -2.2314e-02,\n",
      "         -2.9417e-02, -1.6862e-02,  9.8942e-03,  2.1281e-02,  2.2409e-02,\n",
      "         -1.7693e-02, -5.4450e-03, -7.6170e-03, -1.9194e-02,  2.3469e-02,\n",
      "          2.1461e-02,  1.3401e-02,  1.0629e-02, -2.5625e-03,  3.4874e-03,\n",
      "         -1.6674e-02, -1.2760e-02,  1.8815e-02,  4.1912e-02,  2.0944e-02,\n",
      "          2.2661e-02,  2.6572e-02, -2.3046e-02,  1.4252e-02, -9.7851e-03,\n",
      "         -3.0365e-02, -1.6903e-02, -2.7335e-03,  2.0064e-02, -2.5223e-02,\n",
      "         -3.0762e-02, -2.7992e-02, -3.2706e-02,  2.3870e-02, -5.0680e-03,\n",
      "         -1.1470e-02,  1.0768e-02,  5.4439e-03,  3.1440e-02, -3.2169e-02,\n",
      "         -2.8041e-02, -1.2818e-02,  1.9008e-02,  7.7015e-03, -1.2361e-02,\n",
      "         -3.9342e-02, -3.2623e-02,  2.6036e-02,  2.2309e-02, -1.9554e-02,\n",
      "         -3.7727e-03,  2.3577e-02, -2.9820e-03, -1.0498e-02, -9.8857e-03,\n",
      "          9.3310e-03,  3.3297e-02,  3.1749e-02, -4.8544e-03,  2.9339e-02,\n",
      "          3.8654e-02,  3.4941e-02,  3.0260e-02,  6.1544e-03, -2.4432e-02,\n",
      "          1.0797e-02, -1.0901e-02,  3.7817e-04,  3.8892e-03,  5.1081e-04,\n",
      "          4.0922e-03,  2.7339e-02, -1.9379e-02, -2.4201e-02,  4.3533e-03,\n",
      "          5.5777e-04, -2.3828e-02,  1.7844e-02,  3.0219e-02, -2.5402e-02,\n",
      "          1.9793e-02, -3.3735e-02,  3.3121e-02,  1.9975e-02, -9.9274e-05,\n",
      "          1.6420e-02,  3.9931e-02,  2.4805e-02,  3.1518e-02, -2.5868e-02,\n",
      "          2.1178e-02, -2.2625e-03, -2.9794e-02, -2.0399e-02,  1.0724e-02,\n",
      "         -1.9014e-02,  5.7939e-03,  1.3862e-02,  1.2823e-02, -1.4533e-02,\n",
      "          3.9972e-03, -1.0309e-02,  1.1083e-02, -3.6636e-02, -1.3009e-02,\n",
      "          1.0520e-02,  1.9345e-02,  7.0476e-03,  1.2686e-02,  1.5628e-02,\n",
      "         -1.3945e-02, -7.0663e-03, -6.2368e-03,  1.4412e-02, -2.7064e-02,\n",
      "         -1.8042e-02,  8.1562e-03,  1.8652e-03,  1.5801e-03, -3.1708e-02,\n",
      "         -1.7726e-02, -1.1481e-02,  2.5307e-02,  1.4767e-02,  6.8747e-03,\n",
      "          1.1031e-02,  3.2705e-03,  1.4998e-02, -1.6258e-02, -8.3479e-03,\n",
      "          1.1730e-02,  1.0529e-02,  1.2666e-03,  2.6194e-02, -1.5205e-02,\n",
      "         -1.8807e-02, -2.8112e-02, -2.6295e-02, -7.2598e-03, -1.4114e-03,\n",
      "          1.0073e-02, -1.6898e-02,  2.1371e-02, -3.9751e-04,  1.0728e-02,\n",
      "         -1.7956e-02, -1.7348e-02,  1.5378e-02,  2.1455e-02,  1.0646e-02,\n",
      "          3.3922e-03,  1.6275e-02, -6.9921e-03, -4.1680e-04, -1.1888e-02,\n",
      "          3.9686e-02,  1.0241e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test a forward pass\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    data = training_data[0][0].reshape(-1,3,384,384).to(device)\n",
    "    label = training_data[0][1].reshape(-1,6).to(device)\n",
    "    embed = model(data)\n",
    "    print(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Xy5dsAcpwCri",
   "metadata": {
    "id": "Xy5dsAcpwCri"
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 1e-2\n",
    "margin_loss_learning_rate = 1e-2\n",
    "momentum=0.9\n",
    "weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "WhovjcHqwX91",
   "metadata": {
    "id": "WhovjcHqwX91"
   },
   "outputs": [],
   "source": [
    "training_data_loader = DataLoader(training_data, batch_size, shuffle = True)\n",
    "validation_data_loader = DataLoader(validation_data, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "YenD-SOUwRAV",
   "metadata": {
    "id": "YenD-SOUwRAV"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "margin_loss_regularizer = regularizers.RegularFaceRegularizer()\n",
    "margin_loss_function = losses.ArcFaceLoss(6, 512, margin=34.3, scale=1, weight_regularizer=margin_loss_regularizer).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_optimizer = torch.optim.SGD(margin_loss_function.parameters(), lr=margin_loss_learning_rate)\n",
    "\n",
    "# Schedulers\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, min_lr=1e-8,verbose=True)\n",
    "margin_loss_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, min_lr=1e-8,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "s7NVlZBIwh-F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7NVlZBIwh-F",
    "outputId": "fac89bb8-3837-441f-9fbe-cce03daed593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "training loss: 6.38184\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.99504\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "training loss: 5.82019\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.94047\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "training loss: 5.76879\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.92588\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "training loss: 5.74991\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.92495\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "training loss: 5.73735\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91809\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "training loss: 5.72836\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91515\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "training loss: 5.72875\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91596\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "training loss: 5.72863\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91469\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "training loss: 5.72594\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91379\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "training loss: 5.72323\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91348\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "training loss: 5.72772\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91289\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "training loss: 5.72583\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91229\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "training loss: 5.72388\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91217\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "training loss: 5.72409\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91266\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "training loss: 5.72200\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91183\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "training loss: 5.72791\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91166\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "training loss: 5.72114\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91147\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "training loss: 5.71905\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91164\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "training loss: 5.71964\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91149\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "training loss: 5.71625\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91177\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "training loss: 5.72217\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91112\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "training loss: 5.72516\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91174\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "training loss: 5.71953\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91147\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "training loss: 5.72200\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91211\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "training loss: 5.72455\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91087\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "training loss: 5.72048\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91206\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "training loss: 5.72281\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91069\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "training loss: 5.71990\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91081\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "training loss: 5.72168\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91044\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "training loss: 5.72126\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91057\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "training loss: 5.72058\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91031\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "training loss: 5.72065\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91055\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "training loss: 5.71825\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91015\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "training loss: 5.72170\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91011\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "training loss: 5.71942\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90976\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "training loss: 5.72053\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.91019\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "training loss: 5.71746\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90956\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "training loss: 5.71899\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90983\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "training loss: 5.71632\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90973\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "training loss: 5.72016\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90979\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "training loss: 5.72146\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90966\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "training loss: 5.71883\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90904\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "training loss: 5.71711\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90873\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "training loss: 5.71423\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90878\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "training loss: 5.72351\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90827\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "training loss: 5.71639\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90819\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "training loss: 5.72313\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90809\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "training loss: 5.71577\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90787\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "training loss: 5.71555\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90762\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "training loss: 5.71345\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90755\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "training loss: 5.71296\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90744\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "training loss: 5.71255\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90734\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "training loss: 5.71750\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90724\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "training loss: 5.71519\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90713\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "training loss: 5.71058\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90706\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "training loss: 5.71375\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90700\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "training loss: 5.71486\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90688\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "training loss: 5.71587\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90687\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "training loss: 5.71502\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90675\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "training loss: 5.71493\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90665\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "training loss: 5.71763\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90652\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "training loss: 5.71465\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90651\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "training loss: 5.71238\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90643\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "training loss: 5.71331\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90635\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "training loss: 5.71433\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90621\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "training loss: 5.71070\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90610\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "training loss: 5.71570\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90605\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "training loss: 5.71269\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90588\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "training loss: 5.71238\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90583\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "training loss: 5.71013\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90576\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "training loss: 5.71116\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90565\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "training loss: 5.71391\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90561\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "training loss: 5.71075\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90551\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "training loss: 5.70856\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90543\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "training loss: 5.71061\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90538\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "training loss: 5.71278\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90524\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "training loss: 5.71383\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90525\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "training loss: 5.71253\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90503\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "training loss: 5.70957\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90509\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "training loss: 5.70879\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90488\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "training loss: 5.71039\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90486\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "training loss: 5.71358\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90475\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "training loss: 5.71181\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90468\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "training loss: 5.71180\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90456\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "training loss: 5.71091\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90452\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "training loss: 5.70867\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90446\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "training loss: 5.71191\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90429\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "training loss: 5.71332\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90423\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "training loss: 5.71039\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90416\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "training loss: 5.70968\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90406\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "training loss: 5.71493\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90431\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "training loss: 5.71059\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90421\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "training loss: 5.71169\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90416\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 00093: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "training loss: 5.71086\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90403\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "training loss: 5.71025\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90387\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "training loss: 5.70985\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90373\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "training loss: 5.71192\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90360\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "training loss: 5.71109\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90347\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "training loss: 5.71146\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90333\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "training loss: 5.71247\n",
      "Correct/Total: 67/129\n",
      "Validation Loss:  3.90319\n",
      "Validation Accuracy: 51.93798%\n",
      "\n",
      "Current Best Validation Accuracy: 51.93798%\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(training_data_loader, model, optimizer, margin_loss_function, loss_optimizer)\n",
    "    val_loss = validation(validation_data_loader, model, margin_loss_function)\n",
    "    scheduler.step(val_loss)\n",
    "    # margin_loss_scheduler.step(val_loss)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
